{
  "timestamp": "2024-01-20 16:05:53.849014",
  "type": "python",
  "version": "1.0",
  "name": "Python Test Suite",
  "description": "Checks subtests and graphics",
  "status": "COMPLETED",
  "result": "FAILED",
  "resultMessage": null,
  "details": null,
  "duration": 2.270691394805908,
  "executionDurationReference": 0.020948410034179688,
  "executionDurationStudent": 1.0227551460266113,
  "environment": {
    "Python": "3.10.11",
    "Platform": "Windows-10-10.0.19045-SP0",
    "Packages": {
      "pytest": "7.4.3",
      "pluggy": "1.3.0"
    },
    "Plugins": {
      "json-report": "1.5.0",
      "metadata": "3.0.0"
    }
  },
  "properties": null,
  "debug": null,
  "exitcode": "ExitCode.TESTS_FAILED",
  "summary": {
    "total": 2,
    "success": 0,
    "failed": 1,
    "skipped": 1,
    "timedout": 0
  },
  "tests": [
    {
      "type": "variable",
      "name": "Test Basic 1",
      "description": null,
      "setup": null,
      "teardown": null,
      "status": "COMPLETED",
      "result": "FAILED",
      "resultMessage": null,
      "details": null,
      "executionDurationReference": 0.020948410034179688,
      "executionDurationStudent": 1.0227551460266113,
      "summary": {
        "total": 9,
        "success": 6,
        "failed": 3,
        "skipped": 0,
        "timedout": 0
      },
      "tests": [
        {
          "name": "var1",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "var2",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "var3",
          "status": "COMPLETED",
          "result": "FAILED",
          "resultMessage": null,
          "details": null,
          "longrepr": "self = <tests.test_class.CodeabilityPythonTest object at 0x000002ABD23CFC40>, request = <FixtureRequest for <Function test_entrypoint[testcases2]>>\nrecord_property = <function record_property.<locals>.append_property at 0x000002ABD23DA290>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x000002ABD23CD390>, testcases = (0, 2)\n\n    def test_entrypoint(self, request, record_property, monkeymodule, testcases):\n        idx_main, idx_sub = testcases\n    \n        check_success_dependency(request, idx_main)\n    \n        _report = request.config.stash[report_key]\n        testsuite: CodeAbilityTestSuite = _report[\"testsuite\"]\n        specification: CodeAbilitySpecification = _report[\"specification\"]\n        main: CodeAbilityTestCollection = testsuite.properties.tests[idx_main]\n        sub: CodeAbilityTest = main.tests[idx_sub]\n    \n        dir_reference = specification.testInfo.referenceDirectory\n        dir_student = specification.testInfo.studentDirectory\n    \n        testtype = main.type\n        file = main.file\n    \n        name = sub.name\n        value = sub.value\n        evalString = sub.evalString\n        pattern = sub.pattern\n        countRequirement = sub.countRequirement\n        qualification = sub.qualification\n        relative_tolerance = sub.relativeTolerance\n        absolute_tolerance = sub.absoluteTolerance\n        allowed_occuranceRange = sub.allowedOccuranceRange\n    \n        \"\"\" Get solutions, measure execution time \"\"\"\n        try:\n            solution_student, exec_time_student = get_solution(monkeymodule, request, idx_main, Solution.student)\n            record_property(\"exec_time_student\", exec_time_student)\n            solution_reference, exec_time_reference = get_solution(monkeymodule, request, idx_main, Solution.reference)\n            record_property(\"exec_time_reference\", exec_time_reference)\n        except TimeoutError as e:\n            record_property(\"timeout\", True)\n            raise\n    \n        \"\"\" if test is graphics => get saved graphics object as solution \"\"\"\n        if testtype == TypeEnum.graphics:\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\n            TypeEnum.variable,\n            TypeEnum.graphics,\n            TypeEnum.error,\n            TypeEnum.warning,\n            TypeEnum.help,\n        ]:\n            \"\"\" get the student value \"\"\"\n            if name in solution_student:\n                val_student = solution_student[name]\n            else:\n                \"\"\" value not found, try eval \"\"\"\n                try:\n                    val_student = eval(name, solution_student)\n                except Exception as e:\n                    raise AssertionError(f\"Variable {name} not found in student namespace\")\n    \n            if qualification == QualificationEnum.verifyEqual:\n                \"\"\" get the reference value \"\"\"\n                if value is not None:\n                    val_reference = value\n                elif evalString is not None:\n                    try:\n                        val_reference = eval(evalString)\n                    except Exception as e:\n                        pytest.skip(reason=\"Evaluation of 'evalString' not possible\")\n                else:\n                    if name in solution_reference:\n                        val_reference = solution_reference[name]\n                    else:\n                        try:\n                            val_reference = eval(name, solution_reference)\n                        except Exception as e:\n                            raise AssertionError(f\"Variable {name} not found in reference namespace\")\n    \n                \"\"\" assert variable-type \"\"\"\n                type_student = type(val_student)\n                type_reference = type(val_reference)\n                assert type_student == type_reference, f\"Variable {name} has incorrect type, expected: {type_reference}, obtained {type_student}\"\n    \n                \"\"\" assert variable-value \"\"\"\n                failure_msg = f\"Variable {name} has incorrect value\"\n                if isinstance(val_student, (str, set, frozenset)):\n                    assert val_student == val_reference, failure_msg\n                elif isinstance(val_student, (DataFrame, Series)):\n                    assert val_student.equals(val_reference), failure_msg\n                elif isinstance(val_student, np.ndarray):\n                    try:\n                        if relative_tolerance is None and absolute_tolerance is None:\n                            np.testing.assert_allclose(val_student, val_reference)\n                        else:\n                            np.testing.assert_allclose(val_student, val_reference, rtol=relative_tolerance, atol=absolute_tolerance)\n                    except AssertionError as e:\n                        raise AssertionError(failure_msg)\n                else:\n                    \"\"\"attention: pytest.approx() does not support nested data structures, like: 'var7 = [[1, 22, 44]]' \"\"\"\n>                   assert val_student == pytest.approx(val_reference, rel=relative_tolerance, abs=absolute_tolerance), failure_msg\nE                   AssertionError: Variable var3 has incorrect value\nE                   assert 31 == 98 \u00b1 9.8e-05\nE                     comparison failed\nE                     Obtained: 31\nE                     Expected: 98 \u00b1 9.8e-05\n\ntests\\test_class.py:280: AssertionError"
        },
        {
          "name": "var4",
          "status": "COMPLETED",
          "result": "FAILED",
          "resultMessage": null,
          "details": null,
          "longrepr": "self = <tests.test_class.CodeabilityPythonTest object at 0x000002ABD23D6800>, request = <FixtureRequest for <Function test_entrypoint[testcases3]>>\nrecord_property = <function record_property.<locals>.append_property at 0x000002ABD23DA050>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x000002ABBF91CFA0>, testcases = (0, 3)\n\n    def test_entrypoint(self, request, record_property, monkeymodule, testcases):\n        idx_main, idx_sub = testcases\n    \n        check_success_dependency(request, idx_main)\n    \n        _report = request.config.stash[report_key]\n        testsuite: CodeAbilityTestSuite = _report[\"testsuite\"]\n        specification: CodeAbilitySpecification = _report[\"specification\"]\n        main: CodeAbilityTestCollection = testsuite.properties.tests[idx_main]\n        sub: CodeAbilityTest = main.tests[idx_sub]\n    \n        dir_reference = specification.testInfo.referenceDirectory\n        dir_student = specification.testInfo.studentDirectory\n    \n        testtype = main.type\n        file = main.file\n    \n        name = sub.name\n        value = sub.value\n        evalString = sub.evalString\n        pattern = sub.pattern\n        countRequirement = sub.countRequirement\n        qualification = sub.qualification\n        relative_tolerance = sub.relativeTolerance\n        absolute_tolerance = sub.absoluteTolerance\n        allowed_occuranceRange = sub.allowedOccuranceRange\n    \n        \"\"\" Get solutions, measure execution time \"\"\"\n        try:\n            solution_student, exec_time_student = get_solution(monkeymodule, request, idx_main, Solution.student)\n            record_property(\"exec_time_student\", exec_time_student)\n            solution_reference, exec_time_reference = get_solution(monkeymodule, request, idx_main, Solution.reference)\n            record_property(\"exec_time_reference\", exec_time_reference)\n        except TimeoutError as e:\n            record_property(\"timeout\", True)\n            raise\n    \n        \"\"\" if test is graphics => get saved graphics object as solution \"\"\"\n        if testtype == TypeEnum.graphics:\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\n            TypeEnum.variable,\n            TypeEnum.graphics,\n            TypeEnum.error,\n            TypeEnum.warning,\n            TypeEnum.help,\n        ]:\n            \"\"\" get the student value \"\"\"\n            if name in solution_student:\n                val_student = solution_student[name]\n            else:\n                \"\"\" value not found, try eval \"\"\"\n                try:\n                    val_student = eval(name, solution_student)\n                except Exception as e:\n                    raise AssertionError(f\"Variable {name} not found in student namespace\")\n    \n            if qualification == QualificationEnum.verifyEqual:\n                \"\"\" get the reference value \"\"\"\n                if value is not None:\n                    val_reference = value\n                elif evalString is not None:\n                    try:\n                        val_reference = eval(evalString)\n                    except Exception as e:\n                        pytest.skip(reason=\"Evaluation of 'evalString' not possible\")\n                else:\n                    if name in solution_reference:\n                        val_reference = solution_reference[name]\n                    else:\n                        try:\n                            val_reference = eval(name, solution_reference)\n                        except Exception as e:\n                            raise AssertionError(f\"Variable {name} not found in reference namespace\")\n    \n                \"\"\" assert variable-type \"\"\"\n                type_student = type(val_student)\n                type_reference = type(val_reference)\n                assert type_student == type_reference, f\"Variable {name} has incorrect type, expected: {type_reference}, obtained {type_student}\"\n    \n                \"\"\" assert variable-value \"\"\"\n                failure_msg = f\"Variable {name} has incorrect value\"\n                if isinstance(val_student, (str, set, frozenset)):\n>                   assert val_student == val_reference, failure_msg\nE                   AssertionError: Variable var4 has incorrect value\nE                   assert 'i:\\\\PYTHON\\\\...\\ex1\\\\student' == 'i:\\\\PYTHON\\\\...x1\\\\reference'\nE                     - i:\\PYTHON\\catester\\examples\\ex1\\reference\nE                     ?                                 ^^^^^  ^^\nE                     + i:\\PYTHON\\catester\\examples\\ex1\\student\nE                     ?                                 ^^^^  ^\n\ntests\\test_class.py:267: AssertionError"
        },
        {
          "name": "var5",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "var6[1]",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "var7[0][1]",
          "status": "COMPLETED",
          "result": "FAILED",
          "resultMessage": null,
          "details": null,
          "longrepr": "self = <tests.test_class.CodeabilityPythonTest object at 0x000002ABD23D78E0>, request = <FixtureRequest for <Function test_entrypoint[testcases6]>>\nrecord_property = <function record_property.<locals>.append_property at 0x000002ABD23DA320>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x000002ABD2485180>, testcases = (0, 6)\n\n    def test_entrypoint(self, request, record_property, monkeymodule, testcases):\n        idx_main, idx_sub = testcases\n    \n        check_success_dependency(request, idx_main)\n    \n        _report = request.config.stash[report_key]\n        testsuite: CodeAbilityTestSuite = _report[\"testsuite\"]\n        specification: CodeAbilitySpecification = _report[\"specification\"]\n        main: CodeAbilityTestCollection = testsuite.properties.tests[idx_main]\n        sub: CodeAbilityTest = main.tests[idx_sub]\n    \n        dir_reference = specification.testInfo.referenceDirectory\n        dir_student = specification.testInfo.studentDirectory\n    \n        testtype = main.type\n        file = main.file\n    \n        name = sub.name\n        value = sub.value\n        evalString = sub.evalString\n        pattern = sub.pattern\n        countRequirement = sub.countRequirement\n        qualification = sub.qualification\n        relative_tolerance = sub.relativeTolerance\n        absolute_tolerance = sub.absoluteTolerance\n        allowed_occuranceRange = sub.allowedOccuranceRange\n    \n        \"\"\" Get solutions, measure execution time \"\"\"\n        try:\n            solution_student, exec_time_student = get_solution(monkeymodule, request, idx_main, Solution.student)\n            record_property(\"exec_time_student\", exec_time_student)\n            solution_reference, exec_time_reference = get_solution(monkeymodule, request, idx_main, Solution.reference)\n            record_property(\"exec_time_reference\", exec_time_reference)\n        except TimeoutError as e:\n            record_property(\"timeout\", True)\n            raise\n    \n        \"\"\" if test is graphics => get saved graphics object as solution \"\"\"\n        if testtype == TypeEnum.graphics:\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\n            TypeEnum.variable,\n            TypeEnum.graphics,\n            TypeEnum.error,\n            TypeEnum.warning,\n            TypeEnum.help,\n        ]:\n            \"\"\" get the student value \"\"\"\n            if name in solution_student:\n                val_student = solution_student[name]\n            else:\n                \"\"\" value not found, try eval \"\"\"\n                try:\n                    val_student = eval(name, solution_student)\n                except Exception as e:\n                    raise AssertionError(f\"Variable {name} not found in student namespace\")\n    \n            if qualification == QualificationEnum.verifyEqual:\n                \"\"\" get the reference value \"\"\"\n                if value is not None:\n                    val_reference = value\n                elif evalString is not None:\n                    try:\n                        val_reference = eval(evalString)\n                    except Exception as e:\n                        pytest.skip(reason=\"Evaluation of 'evalString' not possible\")\n                else:\n                    if name in solution_reference:\n                        val_reference = solution_reference[name]\n                    else:\n                        try:\n                            val_reference = eval(name, solution_reference)\n                        except Exception as e:\n                            raise AssertionError(f\"Variable {name} not found in reference namespace\")\n    \n                \"\"\" assert variable-type \"\"\"\n                type_student = type(val_student)\n                type_reference = type(val_reference)\n>               assert type_student == type_reference, f\"Variable {name} has incorrect type, expected: {type_reference}, obtained {type_student}\"\nE               AssertionError: Variable var7[0][1] has incorrect type, expected: <class 'str'>, obtained <class 'int'>\nE               assert <class 'int'> == <class 'str'>\n\ntests\\test_class.py:262: AssertionError"
        },
        {
          "name": "var7[0][2]",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "var8",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        }
      ]
    },
    {
      "type": "variable",
      "name": "Test Basic 2",
      "description": null,
      "setup": null,
      "teardown": null,
      "status": "COMPLETED",
      "result": "SKIPPED",
      "resultMessage": "Tests skipped",
      "details": null,
      "executionDurationReference": 0.0,
      "executionDurationStudent": 0.0,
      "summary": {
        "total": 1,
        "success": 0,
        "failed": 0,
        "skipped": 1,
        "timedout": 0
      },
      "tests": [
        {
          "name": "var9",
          "status": "COMPLETED",
          "result": "SKIPPED",
          "resultMessage": "Test skipped",
          "details": null,
          "longrepr": [
            "i:\\PYTHON\\catester\\catester\\tests\\test_class.py",
            178,
            "Skipped: Dependency ['1'] not satisfied"
          ]
        }
      ]
    }
  ]
}