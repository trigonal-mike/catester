{
  "timestamp": "2024-01-22 16:24:36.240093",
  "type": "python",
  "version": "1.0",
  "name": "Python Test suite",
  "description": "Checks variables",
  "status": "COMPLETED",
  "result": "FAILED",
  "resultMessage": "Some or all tests failed",
  "details": null,
  "duration": 2.021497964859009,
  "executionDurationReference": 0.25003910064697266,
  "executionDurationStudent": 0.3413212299346924,
  "environment": {
    "Python": "3.10.11",
    "Platform": "Windows-10-10.0.19045-SP0",
    "Packages": {
      "pytest": "7.4.3",
      "pluggy": "1.3.0"
    },
    "Plugins": {
      "json-report": "1.5.0",
      "metadata": "3.0.0"
    }
  },
  "properties": null,
  "debug": null,
  "exitcode": "ExitCode.TESTS_FAILED",
  "summary": {
    "total": 6,
    "success": 1,
    "failed": 5,
    "skipped": 0,
    "timedout": 0
  },
  "tests": [
    {
      "type": "variable",
      "name": "Test Basic",
      "description": null,
      "setup": null,
      "teardown": null,
      "status": "COMPLETED",
      "result": "FAILED",
      "resultMessage": null,
      "details": null,
      "executionDurationReference": 0.0027189254760742188,
      "executionDurationStudent": 0.014229536056518555,
      "summary": {
        "total": 8,
        "success": 5,
        "failed": 3,
        "skipped": 0,
        "timedout": 0
      },
      "tests": [
        {
          "name": "var1",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "var2",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "var3",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "var4",
          "status": "COMPLETED",
          "result": "FAILED",
          "resultMessage": null,
          "details": null,
          "longrepr": "self = <tests.test_class.CodeabilityPythonTest object at 0x00000283A7963A60>, request = <FixtureRequest for <Function test_entrypoint[testcases3]>>\nrecord_property = <function record_property.<locals>.append_property at 0x000002839490CDC0>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x00000283A7C7DA80>, testcases = (0, 3)\n\n    def test_entrypoint(self, request, record_property, monkeymodule, testcases):\n        idx_main, idx_sub = testcases\n    \n        check_success_dependency(request, idx_main)\n    \n        _report = request.config.stash[report_key]\n        testsuite: CodeAbilityTestSuite = _report[\"testsuite\"]\n        specification: CodeAbilitySpecification = _report[\"specification\"]\n        main: CodeAbilityTestCollection = testsuite.properties.tests[idx_main]\n        sub: CodeAbilityTest = main.tests[idx_sub]\n    \n        dir_reference = specification.testInfo.referenceDirectory\n        dir_student = specification.testInfo.studentDirectory\n    \n        testtype = main.type\n        file = main.file\n    \n        name = sub.name\n        value = sub.value\n        evalString = sub.evalString\n        pattern = sub.pattern\n        countRequirement = sub.countRequirement\n        qualification = sub.qualification\n        relative_tolerance = sub.relativeTolerance\n        absolute_tolerance = sub.absoluteTolerance\n        allowed_occuranceRange = sub.allowedOccuranceRange\n    \n        \"\"\" Get solutions, measure execution time \"\"\"\n        try:\n            solution_student, exec_time_student = get_solution(monkeymodule, request, idx_main, Solution.student)\n            record_property(\"exec_time_student\", exec_time_student)\n            solution_reference, exec_time_reference = get_solution(monkeymodule, request, idx_main, Solution.reference)\n            record_property(\"exec_time_reference\", exec_time_reference)\n        except TimeoutError as e:\n            record_property(\"timeout\", True)\n            raise\n    \n        \"\"\" if test is graphics => get saved graphics object as solution \"\"\"\n        if testtype == TypeEnum.graphics:\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\n            TypeEnum.variable,\n            TypeEnum.graphics,\n            TypeEnum.error,\n            TypeEnum.warning,\n            TypeEnum.help,\n        ]:\n            \"\"\" get the student value \"\"\"\n            if name in solution_student:\n                val_student = solution_student[name]\n            else:\n                \"\"\" value not found, try eval \"\"\"\n                try:\n>                   val_student = eval(name, solution_student)\n\ncatester\\tests\\test_class.py:237: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\n>   ???\nE   NameError: name 'var4' is not defined\n\n<string>:1: NameError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <tests.test_class.CodeabilityPythonTest object at 0x00000283A7963A60>, request = <FixtureRequest for <Function test_entrypoint[testcases3]>>\nrecord_property = <function record_property.<locals>.append_property at 0x000002839490CDC0>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x00000283A7C7DA80>, testcases = (0, 3)\n\n    def test_entrypoint(self, request, record_property, monkeymodule, testcases):\n        idx_main, idx_sub = testcases\n    \n        check_success_dependency(request, idx_main)\n    \n        _report = request.config.stash[report_key]\n        testsuite: CodeAbilityTestSuite = _report[\"testsuite\"]\n        specification: CodeAbilitySpecification = _report[\"specification\"]\n        main: CodeAbilityTestCollection = testsuite.properties.tests[idx_main]\n        sub: CodeAbilityTest = main.tests[idx_sub]\n    \n        dir_reference = specification.testInfo.referenceDirectory\n        dir_student = specification.testInfo.studentDirectory\n    \n        testtype = main.type\n        file = main.file\n    \n        name = sub.name\n        value = sub.value\n        evalString = sub.evalString\n        pattern = sub.pattern\n        countRequirement = sub.countRequirement\n        qualification = sub.qualification\n        relative_tolerance = sub.relativeTolerance\n        absolute_tolerance = sub.absoluteTolerance\n        allowed_occuranceRange = sub.allowedOccuranceRange\n    \n        \"\"\" Get solutions, measure execution time \"\"\"\n        try:\n            solution_student, exec_time_student = get_solution(monkeymodule, request, idx_main, Solution.student)\n            record_property(\"exec_time_student\", exec_time_student)\n            solution_reference, exec_time_reference = get_solution(monkeymodule, request, idx_main, Solution.reference)\n            record_property(\"exec_time_reference\", exec_time_reference)\n        except TimeoutError as e:\n            record_property(\"timeout\", True)\n            raise\n    \n        \"\"\" if test is graphics => get saved graphics object as solution \"\"\"\n        if testtype == TypeEnum.graphics:\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\n            TypeEnum.variable,\n            TypeEnum.graphics,\n            TypeEnum.error,\n            TypeEnum.warning,\n            TypeEnum.help,\n        ]:\n            \"\"\" get the student value \"\"\"\n            if name in solution_student:\n                val_student = solution_student[name]\n            else:\n                \"\"\" value not found, try eval \"\"\"\n                try:\n                    val_student = eval(name, solution_student)\n                except Exception as e:\n>                   raise AssertionError(f\"Variable {name} not found in student namespace\")\nE                   AssertionError: Variable var4 not found in student namespace\n\ncatester\\tests\\test_class.py:239: AssertionError"
        },
        {
          "name": "var5",
          "status": "COMPLETED",
          "result": "FAILED",
          "resultMessage": null,
          "details": null,
          "longrepr": "self = <tests.test_class.CodeabilityPythonTest object at 0x00000283A7C1F7C0>, request = <FixtureRequest for <Function test_entrypoint[testcases4]>>\nrecord_property = <function record_property.<locals>.append_property at 0x00000283A7C6E8C0>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x00000283A7D4AD10>, testcases = (0, 4)\n\n    def test_entrypoint(self, request, record_property, monkeymodule, testcases):\n        idx_main, idx_sub = testcases\n    \n        check_success_dependency(request, idx_main)\n    \n        _report = request.config.stash[report_key]\n        testsuite: CodeAbilityTestSuite = _report[\"testsuite\"]\n        specification: CodeAbilitySpecification = _report[\"specification\"]\n        main: CodeAbilityTestCollection = testsuite.properties.tests[idx_main]\n        sub: CodeAbilityTest = main.tests[idx_sub]\n    \n        dir_reference = specification.testInfo.referenceDirectory\n        dir_student = specification.testInfo.studentDirectory\n    \n        testtype = main.type\n        file = main.file\n    \n        name = sub.name\n        value = sub.value\n        evalString = sub.evalString\n        pattern = sub.pattern\n        countRequirement = sub.countRequirement\n        qualification = sub.qualification\n        relative_tolerance = sub.relativeTolerance\n        absolute_tolerance = sub.absoluteTolerance\n        allowed_occuranceRange = sub.allowedOccuranceRange\n    \n        \"\"\" Get solutions, measure execution time \"\"\"\n        try:\n            solution_student, exec_time_student = get_solution(monkeymodule, request, idx_main, Solution.student)\n            record_property(\"exec_time_student\", exec_time_student)\n            solution_reference, exec_time_reference = get_solution(monkeymodule, request, idx_main, Solution.reference)\n            record_property(\"exec_time_reference\", exec_time_reference)\n        except TimeoutError as e:\n            record_property(\"timeout\", True)\n            raise\n    \n        \"\"\" if test is graphics => get saved graphics object as solution \"\"\"\n        if testtype == TypeEnum.graphics:\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\n            TypeEnum.variable,\n            TypeEnum.graphics,\n            TypeEnum.error,\n            TypeEnum.warning,\n            TypeEnum.help,\n        ]:\n            \"\"\" get the student value \"\"\"\n            if name in solution_student:\n                val_student = solution_student[name]\n            else:\n                \"\"\" value not found, try eval \"\"\"\n                try:\n                    val_student = eval(name, solution_student)\n                except Exception as e:\n                    raise AssertionError(f\"Variable {name} not found in student namespace\")\n    \n            if qualification == QualificationEnum.verifyEqual:\n                \"\"\" get the reference value \"\"\"\n                if value is not None:\n                    val_reference = value\n                elif evalString is not None:\n                    try:\n                        val_reference = eval(evalString)\n                    except Exception as e:\n                        pytest.skip(reason=\"Evaluation of 'evalString' not possible\")\n                else:\n                    if name in solution_reference:\n                        val_reference = solution_reference[name]\n                    else:\n                        try:\n                            val_reference = eval(name, solution_reference)\n                        except Exception as e:\n                            raise AssertionError(f\"Variable {name} not found in reference namespace\")\n    \n                \"\"\" assert variable-type \"\"\"\n                type_student = type(val_student)\n                type_reference = type(val_reference)\n>               assert type_student == type_reference, f\"Variable {name} has incorrect type, expected: {type_reference}, obtained {type_student}\"\nE               AssertionError: Variable var5 has incorrect type, expected: <class 'tuple'>, obtained <class 'list'>\nE               assert <class 'list'> == <class 'tuple'>\n\ncatester\\tests\\test_class.py:262: AssertionError"
        },
        {
          "name": "var6",
          "status": "COMPLETED",
          "result": "FAILED",
          "resultMessage": null,
          "details": null,
          "longrepr": "self = <tests.test_class.CodeabilityPythonTest object at 0x00000283A7C1CE20>, request = <FixtureRequest for <Function test_entrypoint[testcases5]>>\nrecord_property = <function record_property.<locals>.append_property at 0x000002839490CDC0>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x00000283A7D4F220>, testcases = (0, 5)\n\n    def test_entrypoint(self, request, record_property, monkeymodule, testcases):\n        idx_main, idx_sub = testcases\n    \n        check_success_dependency(request, idx_main)\n    \n        _report = request.config.stash[report_key]\n        testsuite: CodeAbilityTestSuite = _report[\"testsuite\"]\n        specification: CodeAbilitySpecification = _report[\"specification\"]\n        main: CodeAbilityTestCollection = testsuite.properties.tests[idx_main]\n        sub: CodeAbilityTest = main.tests[idx_sub]\n    \n        dir_reference = specification.testInfo.referenceDirectory\n        dir_student = specification.testInfo.studentDirectory\n    \n        testtype = main.type\n        file = main.file\n    \n        name = sub.name\n        value = sub.value\n        evalString = sub.evalString\n        pattern = sub.pattern\n        countRequirement = sub.countRequirement\n        qualification = sub.qualification\n        relative_tolerance = sub.relativeTolerance\n        absolute_tolerance = sub.absoluteTolerance\n        allowed_occuranceRange = sub.allowedOccuranceRange\n    \n        \"\"\" Get solutions, measure execution time \"\"\"\n        try:\n            solution_student, exec_time_student = get_solution(monkeymodule, request, idx_main, Solution.student)\n            record_property(\"exec_time_student\", exec_time_student)\n            solution_reference, exec_time_reference = get_solution(monkeymodule, request, idx_main, Solution.reference)\n            record_property(\"exec_time_reference\", exec_time_reference)\n        except TimeoutError as e:\n            record_property(\"timeout\", True)\n            raise\n    \n        \"\"\" if test is graphics => get saved graphics object as solution \"\"\"\n        if testtype == TypeEnum.graphics:\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\n            TypeEnum.variable,\n            TypeEnum.graphics,\n            TypeEnum.error,\n            TypeEnum.warning,\n            TypeEnum.help,\n        ]:\n            \"\"\" get the student value \"\"\"\n            if name in solution_student:\n                val_student = solution_student[name]\n            else:\n                \"\"\" value not found, try eval \"\"\"\n                try:\n                    val_student = eval(name, solution_student)\n                except Exception as e:\n                    raise AssertionError(f\"Variable {name} not found in student namespace\")\n    \n            if qualification == QualificationEnum.verifyEqual:\n                \"\"\" get the reference value \"\"\"\n                if value is not None:\n                    val_reference = value\n                elif evalString is not None:\n                    try:\n                        val_reference = eval(evalString)\n                    except Exception as e:\n                        pytest.skip(reason=\"Evaluation of 'evalString' not possible\")\n                else:\n                    if name in solution_reference:\n                        val_reference = solution_reference[name]\n                    else:\n                        try:\n                            val_reference = eval(name, solution_reference)\n                        except Exception as e:\n                            raise AssertionError(f\"Variable {name} not found in reference namespace\")\n    \n                \"\"\" assert variable-type \"\"\"\n                type_student = type(val_student)\n                type_reference = type(val_reference)\n                assert type_student == type_reference, f\"Variable {name} has incorrect type, expected: {type_reference}, obtained {type_student}\"\n    \n                \"\"\" assert variable-value \"\"\"\n                failure_msg = f\"Variable {name} has incorrect value\"\n                if isinstance(val_student, (str, set, frozenset)):\n>                   assert val_student == val_reference, failure_msg\nE                   AssertionError: Variable var6 has incorrect value\nE                   assert {1, 2, 3} == {1, 2}\nE                     Extra items in the left set:\nE                     3\nE                     Use -v to get more diff\n\ncatester\\tests\\test_class.py:267: AssertionError"
        },
        {
          "name": "var7",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "var8",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        }
      ]
    },
    {
      "type": "variable",
      "name": "Test PythonTypes",
      "description": null,
      "setup": null,
      "teardown": null,
      "status": "COMPLETED",
      "result": "PASSED",
      "resultMessage": null,
      "details": null,
      "executionDurationReference": 0.015790224075317383,
      "executionDurationStudent": 0.006249666213989258,
      "summary": {
        "total": 15,
        "success": 15,
        "failed": 0,
        "skipped": 0,
        "timedout": 0
      },
      "tests": [
        {
          "name": "x1",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "x2",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "x3",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "x4",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "x5",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "x6",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "x7",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "x8",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "x9",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "x10",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "x11",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "x12",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "x13",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "x14",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "x15",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        }
      ]
    },
    {
      "type": "variable",
      "name": "Test DateTime",
      "description": null,
      "setup": null,
      "teardown": null,
      "status": "COMPLETED",
      "result": "FAILED",
      "resultMessage": null,
      "details": null,
      "executionDurationReference": 0.011663675308227539,
      "executionDurationStudent": 0.01667618751525879,
      "summary": {
        "total": 4,
        "success": 1,
        "failed": 3,
        "skipped": 0,
        "timedout": 0
      },
      "tests": [
        {
          "name": "var_date",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "var_time",
          "status": "COMPLETED",
          "result": "FAILED",
          "resultMessage": null,
          "details": null,
          "longrepr": "self = <tests.test_class.CodeabilityPythonTest object at 0x00000283A7C7D720>, request = <FixtureRequest for <Function test_entrypoint[testcases24]>>\nrecord_property = <function record_property.<locals>.append_property at 0x00000283A7C6E680>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x00000283A7D2F010>, testcases = (2, 1)\n\n    def test_entrypoint(self, request, record_property, monkeymodule, testcases):\n        idx_main, idx_sub = testcases\n    \n        check_success_dependency(request, idx_main)\n    \n        _report = request.config.stash[report_key]\n        testsuite: CodeAbilityTestSuite = _report[\"testsuite\"]\n        specification: CodeAbilitySpecification = _report[\"specification\"]\n        main: CodeAbilityTestCollection = testsuite.properties.tests[idx_main]\n        sub: CodeAbilityTest = main.tests[idx_sub]\n    \n        dir_reference = specification.testInfo.referenceDirectory\n        dir_student = specification.testInfo.studentDirectory\n    \n        testtype = main.type\n        file = main.file\n    \n        name = sub.name\n        value = sub.value\n        evalString = sub.evalString\n        pattern = sub.pattern\n        countRequirement = sub.countRequirement\n        qualification = sub.qualification\n        relative_tolerance = sub.relativeTolerance\n        absolute_tolerance = sub.absoluteTolerance\n        allowed_occuranceRange = sub.allowedOccuranceRange\n    \n        \"\"\" Get solutions, measure execution time \"\"\"\n        try:\n            solution_student, exec_time_student = get_solution(monkeymodule, request, idx_main, Solution.student)\n            record_property(\"exec_time_student\", exec_time_student)\n            solution_reference, exec_time_reference = get_solution(monkeymodule, request, idx_main, Solution.reference)\n            record_property(\"exec_time_reference\", exec_time_reference)\n        except TimeoutError as e:\n            record_property(\"timeout\", True)\n            raise\n    \n        \"\"\" if test is graphics => get saved graphics object as solution \"\"\"\n        if testtype == TypeEnum.graphics:\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\n            TypeEnum.variable,\n            TypeEnum.graphics,\n            TypeEnum.error,\n            TypeEnum.warning,\n            TypeEnum.help,\n        ]:\n            \"\"\" get the student value \"\"\"\n            if name in solution_student:\n                val_student = solution_student[name]\n            else:\n                \"\"\" value not found, try eval \"\"\"\n                try:\n                    val_student = eval(name, solution_student)\n                except Exception as e:\n                    raise AssertionError(f\"Variable {name} not found in student namespace\")\n    \n            if qualification == QualificationEnum.verifyEqual:\n                \"\"\" get the reference value \"\"\"\n                if value is not None:\n                    val_reference = value\n                elif evalString is not None:\n                    try:\n                        val_reference = eval(evalString)\n                    except Exception as e:\n                        pytest.skip(reason=\"Evaluation of 'evalString' not possible\")\n                else:\n                    if name in solution_reference:\n                        val_reference = solution_reference[name]\n                    else:\n                        try:\n                            val_reference = eval(name, solution_reference)\n                        except Exception as e:\n                            raise AssertionError(f\"Variable {name} not found in reference namespace\")\n    \n                \"\"\" assert variable-type \"\"\"\n                type_student = type(val_student)\n                type_reference = type(val_reference)\n                assert type_student == type_reference, f\"Variable {name} has incorrect type, expected: {type_reference}, obtained {type_student}\"\n    \n                \"\"\" assert variable-value \"\"\"\n                failure_msg = f\"Variable {name} has incorrect value\"\n                if isinstance(val_student, (str, set, frozenset)):\n                    assert val_student == val_reference, failure_msg\n                elif isinstance(val_student, (DataFrame, Series)):\n                    assert val_student.equals(val_reference), failure_msg\n                elif isinstance(val_student, np.ndarray):\n                    try:\n                        if relative_tolerance is None and absolute_tolerance is None:\n                            np.testing.assert_allclose(val_student, val_reference)\n                        else:\n                            np.testing.assert_allclose(val_student, val_reference, rtol=relative_tolerance, atol=absolute_tolerance)\n                    except AssertionError as e:\n                        raise AssertionError(failure_msg)\n                else:\n                    \"\"\" attention: pytest.approx() does not support nested data structures, like: 'var7 = [[1, 22, 44]]' \"\"\"\n>                   assert val_student == pytest.approx(val_reference, rel=relative_tolerance, abs=absolute_tolerance), failure_msg\nE                   AssertionError: Variable var_time has incorrect value\nE                   assert datetime.time...4, 37, 504241) == 16:24:37.521916\nE                     comparison failed\nE                     Obtained: 16:24:37.504241\nE                     Expected: 16:24:37.521916\n\ncatester\\tests\\test_class.py:280: AssertionError"
        },
        {
          "name": "var_datetime",
          "status": "COMPLETED",
          "result": "FAILED",
          "resultMessage": null,
          "details": null,
          "longrepr": "self = <tests.test_class.CodeabilityPythonTest object at 0x00000283A7C7D810>, request = <FixtureRequest for <Function test_entrypoint[testcases25]>>\nrecord_property = <function record_property.<locals>.append_property at 0x000002839490CDC0>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x00000283A7D49690>, testcases = (2, 2)\n\n    def test_entrypoint(self, request, record_property, monkeymodule, testcases):\n        idx_main, idx_sub = testcases\n    \n        check_success_dependency(request, idx_main)\n    \n        _report = request.config.stash[report_key]\n        testsuite: CodeAbilityTestSuite = _report[\"testsuite\"]\n        specification: CodeAbilitySpecification = _report[\"specification\"]\n        main: CodeAbilityTestCollection = testsuite.properties.tests[idx_main]\n        sub: CodeAbilityTest = main.tests[idx_sub]\n    \n        dir_reference = specification.testInfo.referenceDirectory\n        dir_student = specification.testInfo.studentDirectory\n    \n        testtype = main.type\n        file = main.file\n    \n        name = sub.name\n        value = sub.value\n        evalString = sub.evalString\n        pattern = sub.pattern\n        countRequirement = sub.countRequirement\n        qualification = sub.qualification\n        relative_tolerance = sub.relativeTolerance\n        absolute_tolerance = sub.absoluteTolerance\n        allowed_occuranceRange = sub.allowedOccuranceRange\n    \n        \"\"\" Get solutions, measure execution time \"\"\"\n        try:\n            solution_student, exec_time_student = get_solution(monkeymodule, request, idx_main, Solution.student)\n            record_property(\"exec_time_student\", exec_time_student)\n            solution_reference, exec_time_reference = get_solution(monkeymodule, request, idx_main, Solution.reference)\n            record_property(\"exec_time_reference\", exec_time_reference)\n        except TimeoutError as e:\n            record_property(\"timeout\", True)\n            raise\n    \n        \"\"\" if test is graphics => get saved graphics object as solution \"\"\"\n        if testtype == TypeEnum.graphics:\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\n            TypeEnum.variable,\n            TypeEnum.graphics,\n            TypeEnum.error,\n            TypeEnum.warning,\n            TypeEnum.help,\n        ]:\n            \"\"\" get the student value \"\"\"\n            if name in solution_student:\n                val_student = solution_student[name]\n            else:\n                \"\"\" value not found, try eval \"\"\"\n                try:\n                    val_student = eval(name, solution_student)\n                except Exception as e:\n                    raise AssertionError(f\"Variable {name} not found in student namespace\")\n    \n            if qualification == QualificationEnum.verifyEqual:\n                \"\"\" get the reference value \"\"\"\n                if value is not None:\n                    val_reference = value\n                elif evalString is not None:\n                    try:\n                        val_reference = eval(evalString)\n                    except Exception as e:\n                        pytest.skip(reason=\"Evaluation of 'evalString' not possible\")\n                else:\n                    if name in solution_reference:\n                        val_reference = solution_reference[name]\n                    else:\n                        try:\n                            val_reference = eval(name, solution_reference)\n                        except Exception as e:\n                            raise AssertionError(f\"Variable {name} not found in reference namespace\")\n    \n                \"\"\" assert variable-type \"\"\"\n                type_student = type(val_student)\n                type_reference = type(val_reference)\n                assert type_student == type_reference, f\"Variable {name} has incorrect type, expected: {type_reference}, obtained {type_student}\"\n    \n                \"\"\" assert variable-value \"\"\"\n                failure_msg = f\"Variable {name} has incorrect value\"\n                if isinstance(val_student, (str, set, frozenset)):\n                    assert val_student == val_reference, failure_msg\n                elif isinstance(val_student, (DataFrame, Series)):\n                    assert val_student.equals(val_reference), failure_msg\n                elif isinstance(val_student, np.ndarray):\n                    try:\n                        if relative_tolerance is None and absolute_tolerance is None:\n                            np.testing.assert_allclose(val_student, val_reference)\n                        else:\n                            np.testing.assert_allclose(val_student, val_reference, rtol=relative_tolerance, atol=absolute_tolerance)\n                    except AssertionError as e:\n                        raise AssertionError(failure_msg)\n                else:\n                    \"\"\" attention: pytest.approx() does not support nested data structures, like: 'var7 = [[1, 22, 44]]' \"\"\"\n>                   assert val_student == pytest.approx(val_reference, rel=relative_tolerance, abs=absolute_tolerance), failure_msg\nE                   AssertionError: Variable var_datetime has incorrect value\nE                   assert datetime.date...4, 37, 504241) == 2024-01-22 16:24:37.521916\nE                     comparison failed\nE                     Obtained: 2024-01-22 16:24:37.504241\nE                     Expected: 2024-01-22 16:24:37.521916\n\ncatester\\tests\\test_class.py:280: AssertionError"
        },
        {
          "name": "var_duration",
          "status": "COMPLETED",
          "result": "FAILED",
          "resultMessage": null,
          "details": null,
          "longrepr": "self = <tests.test_class.CodeabilityPythonTest object at 0x00000283A7C7D8A0>, request = <FixtureRequest for <Function test_entrypoint[testcases26]>>\nrecord_property = <function record_property.<locals>.append_property at 0x00000283A7D1DAB0>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x00000283A7D79600>, testcases = (2, 3)\n\n    def test_entrypoint(self, request, record_property, monkeymodule, testcases):\n        idx_main, idx_sub = testcases\n    \n        check_success_dependency(request, idx_main)\n    \n        _report = request.config.stash[report_key]\n        testsuite: CodeAbilityTestSuite = _report[\"testsuite\"]\n        specification: CodeAbilitySpecification = _report[\"specification\"]\n        main: CodeAbilityTestCollection = testsuite.properties.tests[idx_main]\n        sub: CodeAbilityTest = main.tests[idx_sub]\n    \n        dir_reference = specification.testInfo.referenceDirectory\n        dir_student = specification.testInfo.studentDirectory\n    \n        testtype = main.type\n        file = main.file\n    \n        name = sub.name\n        value = sub.value\n        evalString = sub.evalString\n        pattern = sub.pattern\n        countRequirement = sub.countRequirement\n        qualification = sub.qualification\n        relative_tolerance = sub.relativeTolerance\n        absolute_tolerance = sub.absoluteTolerance\n        allowed_occuranceRange = sub.allowedOccuranceRange\n    \n        \"\"\" Get solutions, measure execution time \"\"\"\n        try:\n            solution_student, exec_time_student = get_solution(monkeymodule, request, idx_main, Solution.student)\n            record_property(\"exec_time_student\", exec_time_student)\n            solution_reference, exec_time_reference = get_solution(monkeymodule, request, idx_main, Solution.reference)\n            record_property(\"exec_time_reference\", exec_time_reference)\n        except TimeoutError as e:\n            record_property(\"timeout\", True)\n            raise\n    \n        \"\"\" if test is graphics => get saved graphics object as solution \"\"\"\n        if testtype == TypeEnum.graphics:\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\n            TypeEnum.variable,\n            TypeEnum.graphics,\n            TypeEnum.error,\n            TypeEnum.warning,\n            TypeEnum.help,\n        ]:\n            \"\"\" get the student value \"\"\"\n            if name in solution_student:\n                val_student = solution_student[name]\n            else:\n                \"\"\" value not found, try eval \"\"\"\n                try:\n                    val_student = eval(name, solution_student)\n                except Exception as e:\n                    raise AssertionError(f\"Variable {name} not found in student namespace\")\n    \n            if qualification == QualificationEnum.verifyEqual:\n                \"\"\" get the reference value \"\"\"\n                if value is not None:\n                    val_reference = value\n                elif evalString is not None:\n                    try:\n                        val_reference = eval(evalString)\n                    except Exception as e:\n                        pytest.skip(reason=\"Evaluation of 'evalString' not possible\")\n                else:\n                    if name in solution_reference:\n                        val_reference = solution_reference[name]\n                    else:\n                        try:\n                            val_reference = eval(name, solution_reference)\n                        except Exception as e:\n                            raise AssertionError(f\"Variable {name} not found in reference namespace\")\n    \n                \"\"\" assert variable-type \"\"\"\n                type_student = type(val_student)\n                type_reference = type(val_reference)\n                assert type_student == type_reference, f\"Variable {name} has incorrect type, expected: {type_reference}, obtained {type_student}\"\n    \n                \"\"\" assert variable-value \"\"\"\n                failure_msg = f\"Variable {name} has incorrect value\"\n                if isinstance(val_student, (str, set, frozenset)):\n                    assert val_student == val_reference, failure_msg\n                elif isinstance(val_student, (DataFrame, Series)):\n                    assert val_student.equals(val_reference), failure_msg\n                elif isinstance(val_student, np.ndarray):\n                    try:\n                        if relative_tolerance is None and absolute_tolerance is None:\n                            np.testing.assert_allclose(val_student, val_reference)\n                        else:\n                            np.testing.assert_allclose(val_student, val_reference, rtol=relative_tolerance, atol=absolute_tolerance)\n                    except AssertionError as e:\n                        raise AssertionError(failure_msg)\n                else:\n                    \"\"\" attention: pytest.approx() does not support nested data structures, like: 'var7 = [[1, 22, 44]]' \"\"\"\n>                   assert val_student == pytest.approx(val_reference, rel=relative_tolerance, abs=absolute_tolerance), failure_msg\nE                   AssertionError: Variable var_duration has incorrect value\nE                   assert datetime.time...croseconds=10) == 5 days, 3:00:00\nE                     comparison failed\nE                     Obtained: 5 days, 3:00:00.000010\nE                     Expected: 5 days, 3:00:00\n\ncatester\\tests\\test_class.py:280: AssertionError"
        }
      ]
    },
    {
      "type": "variable",
      "name": "Test Matplot",
      "description": null,
      "setup": null,
      "teardown": null,
      "status": "COMPLETED",
      "result": "FAILED",
      "resultMessage": null,
      "details": null,
      "executionDurationReference": 0.20306992530822754,
      "executionDurationStudent": 0.2727384567260742,
      "summary": {
        "total": 2,
        "success": 1,
        "failed": 1,
        "skipped": 0,
        "timedout": 0
      },
      "tests": [
        {
          "name": "x",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "y",
          "status": "COMPLETED",
          "result": "FAILED",
          "resultMessage": null,
          "details": null,
          "longrepr": "self = <tests.test_class.CodeabilityPythonTest object at 0x00000283A7C7E6E0>, request = <FixtureRequest for <Function test_entrypoint[testcases28]>>\nrecord_property = <function record_property.<locals>.append_property at 0x00000283A7D1D750>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x00000283AB26A740>, testcases = (3, 1)\n\n    def test_entrypoint(self, request, record_property, monkeymodule, testcases):\n        idx_main, idx_sub = testcases\n    \n        check_success_dependency(request, idx_main)\n    \n        _report = request.config.stash[report_key]\n        testsuite: CodeAbilityTestSuite = _report[\"testsuite\"]\n        specification: CodeAbilitySpecification = _report[\"specification\"]\n        main: CodeAbilityTestCollection = testsuite.properties.tests[idx_main]\n        sub: CodeAbilityTest = main.tests[idx_sub]\n    \n        dir_reference = specification.testInfo.referenceDirectory\n        dir_student = specification.testInfo.studentDirectory\n    \n        testtype = main.type\n        file = main.file\n    \n        name = sub.name\n        value = sub.value\n        evalString = sub.evalString\n        pattern = sub.pattern\n        countRequirement = sub.countRequirement\n        qualification = sub.qualification\n        relative_tolerance = sub.relativeTolerance\n        absolute_tolerance = sub.absoluteTolerance\n        allowed_occuranceRange = sub.allowedOccuranceRange\n    \n        \"\"\" Get solutions, measure execution time \"\"\"\n        try:\n            solution_student, exec_time_student = get_solution(monkeymodule, request, idx_main, Solution.student)\n            record_property(\"exec_time_student\", exec_time_student)\n            solution_reference, exec_time_reference = get_solution(monkeymodule, request, idx_main, Solution.reference)\n            record_property(\"exec_time_reference\", exec_time_reference)\n        except TimeoutError as e:\n            record_property(\"timeout\", True)\n            raise\n    \n        \"\"\" if test is graphics => get saved graphics object as solution \"\"\"\n        if testtype == TypeEnum.graphics:\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\n            TypeEnum.variable,\n            TypeEnum.graphics,\n            TypeEnum.error,\n            TypeEnum.warning,\n            TypeEnum.help,\n        ]:\n            \"\"\" get the student value \"\"\"\n            if name in solution_student:\n                val_student = solution_student[name]\n            else:\n                \"\"\" value not found, try eval \"\"\"\n                try:\n                    val_student = eval(name, solution_student)\n                except Exception as e:\n                    raise AssertionError(f\"Variable {name} not found in student namespace\")\n    \n            if qualification == QualificationEnum.verifyEqual:\n                \"\"\" get the reference value \"\"\"\n                if value is not None:\n                    val_reference = value\n                elif evalString is not None:\n                    try:\n                        val_reference = eval(evalString)\n                    except Exception as e:\n                        pytest.skip(reason=\"Evaluation of 'evalString' not possible\")\n                else:\n                    if name in solution_reference:\n                        val_reference = solution_reference[name]\n                    else:\n                        try:\n                            val_reference = eval(name, solution_reference)\n                        except Exception as e:\n                            raise AssertionError(f\"Variable {name} not found in reference namespace\")\n    \n                \"\"\" assert variable-type \"\"\"\n                type_student = type(val_student)\n                type_reference = type(val_reference)\n                assert type_student == type_reference, f\"Variable {name} has incorrect type, expected: {type_reference}, obtained {type_student}\"\n    \n                \"\"\" assert variable-value \"\"\"\n                failure_msg = f\"Variable {name} has incorrect value\"\n                if isinstance(val_student, (str, set, frozenset)):\n                    assert val_student == val_reference, failure_msg\n                elif isinstance(val_student, (DataFrame, Series)):\n                    assert val_student.equals(val_reference), failure_msg\n                elif isinstance(val_student, np.ndarray):\n                    try:\n                        if relative_tolerance is None and absolute_tolerance is None:\n                            np.testing.assert_allclose(val_student, val_reference)\n                        else:\n>                           np.testing.assert_allclose(val_student, val_reference, rtol=relative_tolerance, atol=absolute_tolerance)\n\ncatester\\tests\\test_class.py:275: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nargs = (<function assert_allclose.<locals>.compare at 0x00000283A7D1DCF0>, array([ 1.00000000e-04,  1.00938420e-01,  2.007488...76008,  0.13146699,  0.03083368, -0.07011396,\n       -0.17034683, -0.26884313, -0.36459873, -0.45663749, -0.54402111]))\nkwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-08, atol=1e-05', 'verbose': True}\n\n    @wraps(func)\n    def inner(*args, **kwds):\n        with self._recreate_cm():\n>           return func(*args, **kwds)\nE           AssertionError: \nE           Not equal to tolerance rtol=1e-08, atol=1e-05\nE           \nE           Mismatched elements: 100 / 100 (100%)\nE           Max absolute difference: 0.0001\nE           Max relative difference: 0.00972825\nE            x: array([ 1.000000e-04,  1.009384e-01,  2.007489e-01,  2.985138e-01,\nE                   3.932366e-01,  4.839516e-01,  5.697341e-01,  6.497095e-01,\nE                   7.230626e-01,  7.890455e-01,  8.469856e-01,  8.962922e-01,...\nE            y: array([ 0.      ,  0.100838,  0.200649,  0.298414,  0.393137,  0.483852,\nE                   0.569634,  0.64961 ,  0.722963,  0.788945,  0.846886,  0.896192,\nE                   0.936363,  0.966988,  0.987755,  0.998452,  0.998971,  0.989306,...\n\nC:\\Users\\Michael\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:79: AssertionError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <tests.test_class.CodeabilityPythonTest object at 0x00000283A7C7E6E0>, request = <FixtureRequest for <Function test_entrypoint[testcases28]>>\nrecord_property = <function record_property.<locals>.append_property at 0x00000283A7D1D750>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x00000283AB26A740>, testcases = (3, 1)\n\n    def test_entrypoint(self, request, record_property, monkeymodule, testcases):\n        idx_main, idx_sub = testcases\n    \n        check_success_dependency(request, idx_main)\n    \n        _report = request.config.stash[report_key]\n        testsuite: CodeAbilityTestSuite = _report[\"testsuite\"]\n        specification: CodeAbilitySpecification = _report[\"specification\"]\n        main: CodeAbilityTestCollection = testsuite.properties.tests[idx_main]\n        sub: CodeAbilityTest = main.tests[idx_sub]\n    \n        dir_reference = specification.testInfo.referenceDirectory\n        dir_student = specification.testInfo.studentDirectory\n    \n        testtype = main.type\n        file = main.file\n    \n        name = sub.name\n        value = sub.value\n        evalString = sub.evalString\n        pattern = sub.pattern\n        countRequirement = sub.countRequirement\n        qualification = sub.qualification\n        relative_tolerance = sub.relativeTolerance\n        absolute_tolerance = sub.absoluteTolerance\n        allowed_occuranceRange = sub.allowedOccuranceRange\n    \n        \"\"\" Get solutions, measure execution time \"\"\"\n        try:\n            solution_student, exec_time_student = get_solution(monkeymodule, request, idx_main, Solution.student)\n            record_property(\"exec_time_student\", exec_time_student)\n            solution_reference, exec_time_reference = get_solution(monkeymodule, request, idx_main, Solution.reference)\n            record_property(\"exec_time_reference\", exec_time_reference)\n        except TimeoutError as e:\n            record_property(\"timeout\", True)\n            raise\n    \n        \"\"\" if test is graphics => get saved graphics object as solution \"\"\"\n        if testtype == TypeEnum.graphics:\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\n            TypeEnum.variable,\n            TypeEnum.graphics,\n            TypeEnum.error,\n            TypeEnum.warning,\n            TypeEnum.help,\n        ]:\n            \"\"\" get the student value \"\"\"\n            if name in solution_student:\n                val_student = solution_student[name]\n            else:\n                \"\"\" value not found, try eval \"\"\"\n                try:\n                    val_student = eval(name, solution_student)\n                except Exception as e:\n                    raise AssertionError(f\"Variable {name} not found in student namespace\")\n    \n            if qualification == QualificationEnum.verifyEqual:\n                \"\"\" get the reference value \"\"\"\n                if value is not None:\n                    val_reference = value\n                elif evalString is not None:\n                    try:\n                        val_reference = eval(evalString)\n                    except Exception as e:\n                        pytest.skip(reason=\"Evaluation of 'evalString' not possible\")\n                else:\n                    if name in solution_reference:\n                        val_reference = solution_reference[name]\n                    else:\n                        try:\n                            val_reference = eval(name, solution_reference)\n                        except Exception as e:\n                            raise AssertionError(f\"Variable {name} not found in reference namespace\")\n    \n                \"\"\" assert variable-type \"\"\"\n                type_student = type(val_student)\n                type_reference = type(val_reference)\n                assert type_student == type_reference, f\"Variable {name} has incorrect type, expected: {type_reference}, obtained {type_student}\"\n    \n                \"\"\" assert variable-value \"\"\"\n                failure_msg = f\"Variable {name} has incorrect value\"\n                if isinstance(val_student, (str, set, frozenset)):\n                    assert val_student == val_reference, failure_msg\n                elif isinstance(val_student, (DataFrame, Series)):\n                    assert val_student.equals(val_reference), failure_msg\n                elif isinstance(val_student, np.ndarray):\n                    try:\n                        if relative_tolerance is None and absolute_tolerance is None:\n                            np.testing.assert_allclose(val_student, val_reference)\n                        else:\n                            np.testing.assert_allclose(val_student, val_reference, rtol=relative_tolerance, atol=absolute_tolerance)\n                    except AssertionError as e:\n>                       raise AssertionError(failure_msg)\nE                       AssertionError: Variable y has incorrect value\n\ncatester\\tests\\test_class.py:277: AssertionError"
        }
      ]
    },
    {
      "type": "variable",
      "name": "Test Pandas",
      "description": null,
      "setup": null,
      "teardown": null,
      "status": "COMPLETED",
      "result": "FAILED",
      "resultMessage": null,
      "details": null,
      "executionDurationReference": 0.016796350479125977,
      "executionDurationStudent": 0.015579462051391602,
      "summary": {
        "total": 2,
        "success": 1,
        "failed": 1,
        "skipped": 0,
        "timedout": 0
      },
      "tests": [
        {
          "name": "df",
          "status": "COMPLETED",
          "result": "FAILED",
          "resultMessage": null,
          "details": null,
          "longrepr": "self = <tests.test_class.CodeabilityPythonTest object at 0x00000283A7C7E980>, request = <FixtureRequest for <Function test_entrypoint[testcases29]>>\nrecord_property = <function record_property.<locals>.append_property at 0x00000283A7EDD750>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x00000283AB2E2680>, testcases = (4, 0)\n\n    def test_entrypoint(self, request, record_property, monkeymodule, testcases):\n        idx_main, idx_sub = testcases\n    \n        check_success_dependency(request, idx_main)\n    \n        _report = request.config.stash[report_key]\n        testsuite: CodeAbilityTestSuite = _report[\"testsuite\"]\n        specification: CodeAbilitySpecification = _report[\"specification\"]\n        main: CodeAbilityTestCollection = testsuite.properties.tests[idx_main]\n        sub: CodeAbilityTest = main.tests[idx_sub]\n    \n        dir_reference = specification.testInfo.referenceDirectory\n        dir_student = specification.testInfo.studentDirectory\n    \n        testtype = main.type\n        file = main.file\n    \n        name = sub.name\n        value = sub.value\n        evalString = sub.evalString\n        pattern = sub.pattern\n        countRequirement = sub.countRequirement\n        qualification = sub.qualification\n        relative_tolerance = sub.relativeTolerance\n        absolute_tolerance = sub.absoluteTolerance\n        allowed_occuranceRange = sub.allowedOccuranceRange\n    \n        \"\"\" Get solutions, measure execution time \"\"\"\n        try:\n            solution_student, exec_time_student = get_solution(monkeymodule, request, idx_main, Solution.student)\n            record_property(\"exec_time_student\", exec_time_student)\n            solution_reference, exec_time_reference = get_solution(monkeymodule, request, idx_main, Solution.reference)\n            record_property(\"exec_time_reference\", exec_time_reference)\n        except TimeoutError as e:\n            record_property(\"timeout\", True)\n            raise\n    \n        \"\"\" if test is graphics => get saved graphics object as solution \"\"\"\n        if testtype == TypeEnum.graphics:\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\n            TypeEnum.variable,\n            TypeEnum.graphics,\n            TypeEnum.error,\n            TypeEnum.warning,\n            TypeEnum.help,\n        ]:\n            \"\"\" get the student value \"\"\"\n            if name in solution_student:\n                val_student = solution_student[name]\n            else:\n                \"\"\" value not found, try eval \"\"\"\n                try:\n                    val_student = eval(name, solution_student)\n                except Exception as e:\n                    raise AssertionError(f\"Variable {name} not found in student namespace\")\n    \n            if qualification == QualificationEnum.verifyEqual:\n                \"\"\" get the reference value \"\"\"\n                if value is not None:\n                    val_reference = value\n                elif evalString is not None:\n                    try:\n                        val_reference = eval(evalString)\n                    except Exception as e:\n                        pytest.skip(reason=\"Evaluation of 'evalString' not possible\")\n                else:\n                    if name in solution_reference:\n                        val_reference = solution_reference[name]\n                    else:\n                        try:\n                            val_reference = eval(name, solution_reference)\n                        except Exception as e:\n                            raise AssertionError(f\"Variable {name} not found in reference namespace\")\n    \n                \"\"\" assert variable-type \"\"\"\n                type_student = type(val_student)\n                type_reference = type(val_reference)\n                assert type_student == type_reference, f\"Variable {name} has incorrect type, expected: {type_reference}, obtained {type_student}\"\n    \n                \"\"\" assert variable-value \"\"\"\n                failure_msg = f\"Variable {name} has incorrect value\"\n                if isinstance(val_student, (str, set, frozenset)):\n                    assert val_student == val_reference, failure_msg\n                elif isinstance(val_student, (DataFrame, Series)):\n>                   assert val_student.equals(val_reference), failure_msg\nE                   AssertionError: Variable df has incorrect value\nE                   assert False\nE                    +  where False = <bound method NDFrame.equals of    Column1 Column2  Column3\\n0        1       a     True\\n1        2       B    False\\n2        3       C     True>(   Column1 Column2  Column3\\n0        1       A     True\\n1        2       B    False\\n2        3       C     True)\nE                    +    where <bound method NDFrame.equals of    Column1 Column2  Column3\\n0        1       a     True\\n1        2       B    False\\n2        3       C     True> =    Column1 Column2  Column3\\n0        1       a     True\\n1        2       B    False\\n2        3       C     True.equals\n\ncatester\\tests\\test_class.py:269: AssertionError"
        },
        {
          "name": "ser",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        }
      ]
    },
    {
      "type": "variable",
      "name": "Test Strings",
      "description": null,
      "setup": null,
      "teardown": null,
      "status": "COMPLETED",
      "result": "FAILED",
      "resultMessage": null,
      "details": null,
      "executionDurationReference": 0.0,
      "executionDurationStudent": 0.01584792137145996,
      "summary": {
        "total": 12,
        "success": 6,
        "failed": 6,
        "skipped": 0,
        "timedout": 0
      },
      "tests": [
        {
          "name": "var1",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "var1",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "var1",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "var1",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "var1",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "var1",
          "status": "COMPLETED",
          "result": "PASSED",
          "resultMessage": null,
          "details": null,
          "longrepr": null
        },
        {
          "name": "var2",
          "status": "COMPLETED",
          "result": "FAILED",
          "resultMessage": null,
          "details": null,
          "longrepr": "self = <tests.test_class.CodeabilityPythonTest object at 0x00000283A7C7CF70>, request = <FixtureRequest for <Function test_entrypoint[testcases37]>>\nrecord_property = <function record_property.<locals>.append_property at 0x00000283A7EDCC10>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x00000283A7D49C90>, testcases = (5, 6)\n\n    def test_entrypoint(self, request, record_property, monkeymodule, testcases):\n        idx_main, idx_sub = testcases\n    \n        check_success_dependency(request, idx_main)\n    \n        _report = request.config.stash[report_key]\n        testsuite: CodeAbilityTestSuite = _report[\"testsuite\"]\n        specification: CodeAbilitySpecification = _report[\"specification\"]\n        main: CodeAbilityTestCollection = testsuite.properties.tests[idx_main]\n        sub: CodeAbilityTest = main.tests[idx_sub]\n    \n        dir_reference = specification.testInfo.referenceDirectory\n        dir_student = specification.testInfo.studentDirectory\n    \n        testtype = main.type\n        file = main.file\n    \n        name = sub.name\n        value = sub.value\n        evalString = sub.evalString\n        pattern = sub.pattern\n        countRequirement = sub.countRequirement\n        qualification = sub.qualification\n        relative_tolerance = sub.relativeTolerance\n        absolute_tolerance = sub.absoluteTolerance\n        allowed_occuranceRange = sub.allowedOccuranceRange\n    \n        \"\"\" Get solutions, measure execution time \"\"\"\n        try:\n            solution_student, exec_time_student = get_solution(monkeymodule, request, idx_main, Solution.student)\n            record_property(\"exec_time_student\", exec_time_student)\n            solution_reference, exec_time_reference = get_solution(monkeymodule, request, idx_main, Solution.reference)\n            record_property(\"exec_time_reference\", exec_time_reference)\n        except TimeoutError as e:\n            record_property(\"timeout\", True)\n            raise\n    \n        \"\"\" if test is graphics => get saved graphics object as solution \"\"\"\n        if testtype == TypeEnum.graphics:\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\n            TypeEnum.variable,\n            TypeEnum.graphics,\n            TypeEnum.error,\n            TypeEnum.warning,\n            TypeEnum.help,\n        ]:\n            \"\"\" get the student value \"\"\"\n            if name in solution_student:\n                val_student = solution_student[name]\n            else:\n                \"\"\" value not found, try eval \"\"\"\n                try:\n                    val_student = eval(name, solution_student)\n                except Exception as e:\n                    raise AssertionError(f\"Variable {name} not found in student namespace\")\n    \n            if qualification == QualificationEnum.verifyEqual:\n                \"\"\" get the reference value \"\"\"\n                if value is not None:\n                    val_reference = value\n                elif evalString is not None:\n                    try:\n                        val_reference = eval(evalString)\n                    except Exception as e:\n                        pytest.skip(reason=\"Evaluation of 'evalString' not possible\")\n                else:\n                    if name in solution_reference:\n                        val_reference = solution_reference[name]\n                    else:\n                        try:\n                            val_reference = eval(name, solution_reference)\n                        except Exception as e:\n                            raise AssertionError(f\"Variable {name} not found in reference namespace\")\n    \n                \"\"\" assert variable-type \"\"\"\n                type_student = type(val_student)\n                type_reference = type(val_reference)\n                assert type_student == type_reference, f\"Variable {name} has incorrect type, expected: {type_reference}, obtained {type_student}\"\n    \n                \"\"\" assert variable-value \"\"\"\n                failure_msg = f\"Variable {name} has incorrect value\"\n                if isinstance(val_student, (str, set, frozenset)):\n                    assert val_student == val_reference, failure_msg\n                elif isinstance(val_student, (DataFrame, Series)):\n                    assert val_student.equals(val_reference), failure_msg\n                elif isinstance(val_student, np.ndarray):\n                    try:\n                        if relative_tolerance is None and absolute_tolerance is None:\n                            np.testing.assert_allclose(val_student, val_reference)\n                        else:\n                            np.testing.assert_allclose(val_student, val_reference, rtol=relative_tolerance, atol=absolute_tolerance)\n                    except AssertionError as e:\n                        raise AssertionError(failure_msg)\n                else:\n                    \"\"\" attention: pytest.approx() does not support nested data structures, like: 'var7 = [[1, 22, 44]]' \"\"\"\n                    assert val_student == pytest.approx(val_reference, rel=relative_tolerance, abs=absolute_tolerance), failure_msg\n            elif qualification == QualificationEnum.matches:\n>               assert str(val_student) == pattern, f\"Variable {name} does not match the specified pattern {pattern}\"\nE               AssertionError: Variable var2 does not match the specified pattern -\nE               assert '_x1234567890' == '-'\nE                 - -\nE                 + _x1234567890\n\ncatester\\tests\\test_class.py:282: AssertionError"
        },
        {
          "name": "var2",
          "status": "COMPLETED",
          "result": "FAILED",
          "resultMessage": null,
          "details": null,
          "longrepr": "self = <tests.test_class.CodeabilityPythonTest object at 0x00000283A7C7D000>, request = <FixtureRequest for <Function test_entrypoint[testcases38]>>\nrecord_property = <function record_property.<locals>.append_property at 0x00000283A7EDF520>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x00000283AB124C10>, testcases = (5, 7)\n\n    def test_entrypoint(self, request, record_property, monkeymodule, testcases):\n        idx_main, idx_sub = testcases\n    \n        check_success_dependency(request, idx_main)\n    \n        _report = request.config.stash[report_key]\n        testsuite: CodeAbilityTestSuite = _report[\"testsuite\"]\n        specification: CodeAbilitySpecification = _report[\"specification\"]\n        main: CodeAbilityTestCollection = testsuite.properties.tests[idx_main]\n        sub: CodeAbilityTest = main.tests[idx_sub]\n    \n        dir_reference = specification.testInfo.referenceDirectory\n        dir_student = specification.testInfo.studentDirectory\n    \n        testtype = main.type\n        file = main.file\n    \n        name = sub.name\n        value = sub.value\n        evalString = sub.evalString\n        pattern = sub.pattern\n        countRequirement = sub.countRequirement\n        qualification = sub.qualification\n        relative_tolerance = sub.relativeTolerance\n        absolute_tolerance = sub.absoluteTolerance\n        allowed_occuranceRange = sub.allowedOccuranceRange\n    \n        \"\"\" Get solutions, measure execution time \"\"\"\n        try:\n            solution_student, exec_time_student = get_solution(monkeymodule, request, idx_main, Solution.student)\n            record_property(\"exec_time_student\", exec_time_student)\n            solution_reference, exec_time_reference = get_solution(monkeymodule, request, idx_main, Solution.reference)\n            record_property(\"exec_time_reference\", exec_time_reference)\n        except TimeoutError as e:\n            record_property(\"timeout\", True)\n            raise\n    \n        \"\"\" if test is graphics => get saved graphics object as solution \"\"\"\n        if testtype == TypeEnum.graphics:\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\n            TypeEnum.variable,\n            TypeEnum.graphics,\n            TypeEnum.error,\n            TypeEnum.warning,\n            TypeEnum.help,\n        ]:\n            \"\"\" get the student value \"\"\"\n            if name in solution_student:\n                val_student = solution_student[name]\n            else:\n                \"\"\" value not found, try eval \"\"\"\n                try:\n                    val_student = eval(name, solution_student)\n                except Exception as e:\n                    raise AssertionError(f\"Variable {name} not found in student namespace\")\n    \n            if qualification == QualificationEnum.verifyEqual:\n                \"\"\" get the reference value \"\"\"\n                if value is not None:\n                    val_reference = value\n                elif evalString is not None:\n                    try:\n                        val_reference = eval(evalString)\n                    except Exception as e:\n                        pytest.skip(reason=\"Evaluation of 'evalString' not possible\")\n                else:\n                    if name in solution_reference:\n                        val_reference = solution_reference[name]\n                    else:\n                        try:\n                            val_reference = eval(name, solution_reference)\n                        except Exception as e:\n                            raise AssertionError(f\"Variable {name} not found in reference namespace\")\n    \n                \"\"\" assert variable-type \"\"\"\n                type_student = type(val_student)\n                type_reference = type(val_reference)\n                assert type_student == type_reference, f\"Variable {name} has incorrect type, expected: {type_reference}, obtained {type_student}\"\n    \n                \"\"\" assert variable-value \"\"\"\n                failure_msg = f\"Variable {name} has incorrect value\"\n                if isinstance(val_student, (str, set, frozenset)):\n                    assert val_student == val_reference, failure_msg\n                elif isinstance(val_student, (DataFrame, Series)):\n                    assert val_student.equals(val_reference), failure_msg\n                elif isinstance(val_student, np.ndarray):\n                    try:\n                        if relative_tolerance is None and absolute_tolerance is None:\n                            np.testing.assert_allclose(val_student, val_reference)\n                        else:\n                            np.testing.assert_allclose(val_student, val_reference, rtol=relative_tolerance, atol=absolute_tolerance)\n                    except AssertionError as e:\n                        raise AssertionError(failure_msg)\n                else:\n                    \"\"\" attention: pytest.approx() does not support nested data structures, like: 'var7 = [[1, 22, 44]]' \"\"\"\n                    assert val_student == pytest.approx(val_reference, rel=relative_tolerance, abs=absolute_tolerance), failure_msg\n            elif qualification == QualificationEnum.matches:\n                assert str(val_student) == pattern, f\"Variable {name} does not match the specified pattern {pattern}\"\n            elif qualification == QualificationEnum.contains:\n>               assert str(val_student).find(pattern) > -1, f\"Variable {name} does not contain the specified pattern {pattern}\"\nE               AssertionError: Variable var2 does not contain the specified pattern -\nE               assert -1 > -1\nE                +  where -1 = <built-in method find of str object at 0x00000283A7D998F0>('-')\nE                +    where <built-in method find of str object at 0x00000283A7D998F0> = '_x1234567890'.find\nE                +      where '_x1234567890' = str('_x1234567890')\n\ncatester\\tests\\test_class.py:284: AssertionError"
        },
        {
          "name": "var2",
          "status": "COMPLETED",
          "result": "FAILED",
          "resultMessage": null,
          "details": null,
          "longrepr": "self = <tests.test_class.CodeabilityPythonTest object at 0x00000283A7C7D930>, request = <FixtureRequest for <Function test_entrypoint[testcases39]>>\nrecord_property = <function record_property.<locals>.append_property at 0x00000283A7EDC280>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x00000283AB354970>, testcases = (5, 8)\n\n    def test_entrypoint(self, request, record_property, monkeymodule, testcases):\n        idx_main, idx_sub = testcases\n    \n        check_success_dependency(request, idx_main)\n    \n        _report = request.config.stash[report_key]\n        testsuite: CodeAbilityTestSuite = _report[\"testsuite\"]\n        specification: CodeAbilitySpecification = _report[\"specification\"]\n        main: CodeAbilityTestCollection = testsuite.properties.tests[idx_main]\n        sub: CodeAbilityTest = main.tests[idx_sub]\n    \n        dir_reference = specification.testInfo.referenceDirectory\n        dir_student = specification.testInfo.studentDirectory\n    \n        testtype = main.type\n        file = main.file\n    \n        name = sub.name\n        value = sub.value\n        evalString = sub.evalString\n        pattern = sub.pattern\n        countRequirement = sub.countRequirement\n        qualification = sub.qualification\n        relative_tolerance = sub.relativeTolerance\n        absolute_tolerance = sub.absoluteTolerance\n        allowed_occuranceRange = sub.allowedOccuranceRange\n    \n        \"\"\" Get solutions, measure execution time \"\"\"\n        try:\n            solution_student, exec_time_student = get_solution(monkeymodule, request, idx_main, Solution.student)\n            record_property(\"exec_time_student\", exec_time_student)\n            solution_reference, exec_time_reference = get_solution(monkeymodule, request, idx_main, Solution.reference)\n            record_property(\"exec_time_reference\", exec_time_reference)\n        except TimeoutError as e:\n            record_property(\"timeout\", True)\n            raise\n    \n        \"\"\" if test is graphics => get saved graphics object as solution \"\"\"\n        if testtype == TypeEnum.graphics:\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\n            TypeEnum.variable,\n            TypeEnum.graphics,\n            TypeEnum.error,\n            TypeEnum.warning,\n            TypeEnum.help,\n        ]:\n            \"\"\" get the student value \"\"\"\n            if name in solution_student:\n                val_student = solution_student[name]\n            else:\n                \"\"\" value not found, try eval \"\"\"\n                try:\n                    val_student = eval(name, solution_student)\n                except Exception as e:\n                    raise AssertionError(f\"Variable {name} not found in student namespace\")\n    \n            if qualification == QualificationEnum.verifyEqual:\n                \"\"\" get the reference value \"\"\"\n                if value is not None:\n                    val_reference = value\n                elif evalString is not None:\n                    try:\n                        val_reference = eval(evalString)\n                    except Exception as e:\n                        pytest.skip(reason=\"Evaluation of 'evalString' not possible\")\n                else:\n                    if name in solution_reference:\n                        val_reference = solution_reference[name]\n                    else:\n                        try:\n                            val_reference = eval(name, solution_reference)\n                        except Exception as e:\n                            raise AssertionError(f\"Variable {name} not found in reference namespace\")\n    \n                \"\"\" assert variable-type \"\"\"\n                type_student = type(val_student)\n                type_reference = type(val_reference)\n                assert type_student == type_reference, f\"Variable {name} has incorrect type, expected: {type_reference}, obtained {type_student}\"\n    \n                \"\"\" assert variable-value \"\"\"\n                failure_msg = f\"Variable {name} has incorrect value\"\n                if isinstance(val_student, (str, set, frozenset)):\n                    assert val_student == val_reference, failure_msg\n                elif isinstance(val_student, (DataFrame, Series)):\n                    assert val_student.equals(val_reference), failure_msg\n                elif isinstance(val_student, np.ndarray):\n                    try:\n                        if relative_tolerance is None and absolute_tolerance is None:\n                            np.testing.assert_allclose(val_student, val_reference)\n                        else:\n                            np.testing.assert_allclose(val_student, val_reference, rtol=relative_tolerance, atol=absolute_tolerance)\n                    except AssertionError as e:\n                        raise AssertionError(failure_msg)\n                else:\n                    \"\"\" attention: pytest.approx() does not support nested data structures, like: 'var7 = [[1, 22, 44]]' \"\"\"\n                    assert val_student == pytest.approx(val_reference, rel=relative_tolerance, abs=absolute_tolerance), failure_msg\n            elif qualification == QualificationEnum.matches:\n                assert str(val_student) == pattern, f\"Variable {name} does not match the specified pattern {pattern}\"\n            elif qualification == QualificationEnum.contains:\n                assert str(val_student).find(pattern) > -1, f\"Variable {name} does not contain the specified pattern {pattern}\"\n            elif qualification == QualificationEnum.startsWith:\n>               assert str(val_student).startswith(pattern), f\"Variable {name} does not start with the specified pattern {pattern}\"\nE               AssertionError: Variable var2 does not start with the specified pattern -\nE               assert False\nE                +  where False = <built-in method startswith of str object at 0x00000283A7D998F0>('-')\nE                +    where <built-in method startswith of str object at 0x00000283A7D998F0> = '_x1234567890'.startswith\nE                +      where '_x1234567890' = str('_x1234567890')\n\ncatester\\tests\\test_class.py:286: AssertionError"
        },
        {
          "name": "var2",
          "status": "COMPLETED",
          "result": "FAILED",
          "resultMessage": null,
          "details": null,
          "longrepr": "self = <tests.test_class.CodeabilityPythonTest object at 0x00000283A7C7DA20>, request = <FixtureRequest for <Function test_entrypoint[testcases40]>>\nrecord_property = <function record_property.<locals>.append_property at 0x00000283A7EDCEE0>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x00000283A7D2F580>, testcases = (5, 9)\n\n    def test_entrypoint(self, request, record_property, monkeymodule, testcases):\n        idx_main, idx_sub = testcases\n    \n        check_success_dependency(request, idx_main)\n    \n        _report = request.config.stash[report_key]\n        testsuite: CodeAbilityTestSuite = _report[\"testsuite\"]\n        specification: CodeAbilitySpecification = _report[\"specification\"]\n        main: CodeAbilityTestCollection = testsuite.properties.tests[idx_main]\n        sub: CodeAbilityTest = main.tests[idx_sub]\n    \n        dir_reference = specification.testInfo.referenceDirectory\n        dir_student = specification.testInfo.studentDirectory\n    \n        testtype = main.type\n        file = main.file\n    \n        name = sub.name\n        value = sub.value\n        evalString = sub.evalString\n        pattern = sub.pattern\n        countRequirement = sub.countRequirement\n        qualification = sub.qualification\n        relative_tolerance = sub.relativeTolerance\n        absolute_tolerance = sub.absoluteTolerance\n        allowed_occuranceRange = sub.allowedOccuranceRange\n    \n        \"\"\" Get solutions, measure execution time \"\"\"\n        try:\n            solution_student, exec_time_student = get_solution(monkeymodule, request, idx_main, Solution.student)\n            record_property(\"exec_time_student\", exec_time_student)\n            solution_reference, exec_time_reference = get_solution(monkeymodule, request, idx_main, Solution.reference)\n            record_property(\"exec_time_reference\", exec_time_reference)\n        except TimeoutError as e:\n            record_property(\"timeout\", True)\n            raise\n    \n        \"\"\" if test is graphics => get saved graphics object as solution \"\"\"\n        if testtype == TypeEnum.graphics:\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\n            TypeEnum.variable,\n            TypeEnum.graphics,\n            TypeEnum.error,\n            TypeEnum.warning,\n            TypeEnum.help,\n        ]:\n            \"\"\" get the student value \"\"\"\n            if name in solution_student:\n                val_student = solution_student[name]\n            else:\n                \"\"\" value not found, try eval \"\"\"\n                try:\n                    val_student = eval(name, solution_student)\n                except Exception as e:\n                    raise AssertionError(f\"Variable {name} not found in student namespace\")\n    \n            if qualification == QualificationEnum.verifyEqual:\n                \"\"\" get the reference value \"\"\"\n                if value is not None:\n                    val_reference = value\n                elif evalString is not None:\n                    try:\n                        val_reference = eval(evalString)\n                    except Exception as e:\n                        pytest.skip(reason=\"Evaluation of 'evalString' not possible\")\n                else:\n                    if name in solution_reference:\n                        val_reference = solution_reference[name]\n                    else:\n                        try:\n                            val_reference = eval(name, solution_reference)\n                        except Exception as e:\n                            raise AssertionError(f\"Variable {name} not found in reference namespace\")\n    \n                \"\"\" assert variable-type \"\"\"\n                type_student = type(val_student)\n                type_reference = type(val_reference)\n                assert type_student == type_reference, f\"Variable {name} has incorrect type, expected: {type_reference}, obtained {type_student}\"\n    \n                \"\"\" assert variable-value \"\"\"\n                failure_msg = f\"Variable {name} has incorrect value\"\n                if isinstance(val_student, (str, set, frozenset)):\n                    assert val_student == val_reference, failure_msg\n                elif isinstance(val_student, (DataFrame, Series)):\n                    assert val_student.equals(val_reference), failure_msg\n                elif isinstance(val_student, np.ndarray):\n                    try:\n                        if relative_tolerance is None and absolute_tolerance is None:\n                            np.testing.assert_allclose(val_student, val_reference)\n                        else:\n                            np.testing.assert_allclose(val_student, val_reference, rtol=relative_tolerance, atol=absolute_tolerance)\n                    except AssertionError as e:\n                        raise AssertionError(failure_msg)\n                else:\n                    \"\"\" attention: pytest.approx() does not support nested data structures, like: 'var7 = [[1, 22, 44]]' \"\"\"\n                    assert val_student == pytest.approx(val_reference, rel=relative_tolerance, abs=absolute_tolerance), failure_msg\n            elif qualification == QualificationEnum.matches:\n                assert str(val_student) == pattern, f\"Variable {name} does not match the specified pattern {pattern}\"\n            elif qualification == QualificationEnum.contains:\n                assert str(val_student).find(pattern) > -1, f\"Variable {name} does not contain the specified pattern {pattern}\"\n            elif qualification == QualificationEnum.startsWith:\n                assert str(val_student).startswith(pattern), f\"Variable {name} does not start with the specified pattern {pattern}\"\n            elif qualification == QualificationEnum.endsWith:\n>               assert str(val_student).endswith(pattern), f\"Variable {name} does not end with the specified pattern {pattern}\"\nE               AssertionError: Variable var2 does not end with the specified pattern -\nE               assert False\nE                +  where False = <built-in method endswith of str object at 0x00000283A7D998F0>('-')\nE                +    where <built-in method endswith of str object at 0x00000283A7D998F0> = '_x1234567890'.endswith\nE                +      where '_x1234567890' = str('_x1234567890')\n\ncatester\\tests\\test_class.py:288: AssertionError"
        },
        {
          "name": "var2",
          "status": "COMPLETED",
          "result": "FAILED",
          "resultMessage": null,
          "details": null,
          "longrepr": "self = <tests.test_class.CodeabilityPythonTest object at 0x00000283A7C7DAB0>, request = <FixtureRequest for <Function test_entrypoint[testcases41]>>\nrecord_property = <function record_property.<locals>.append_property at 0x00000283A7EDC0D0>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x00000283A7D4AE60>, testcases = (5, 10)\n\n    def test_entrypoint(self, request, record_property, monkeymodule, testcases):\n        idx_main, idx_sub = testcases\n    \n        check_success_dependency(request, idx_main)\n    \n        _report = request.config.stash[report_key]\n        testsuite: CodeAbilityTestSuite = _report[\"testsuite\"]\n        specification: CodeAbilitySpecification = _report[\"specification\"]\n        main: CodeAbilityTestCollection = testsuite.properties.tests[idx_main]\n        sub: CodeAbilityTest = main.tests[idx_sub]\n    \n        dir_reference = specification.testInfo.referenceDirectory\n        dir_student = specification.testInfo.studentDirectory\n    \n        testtype = main.type\n        file = main.file\n    \n        name = sub.name\n        value = sub.value\n        evalString = sub.evalString\n        pattern = sub.pattern\n        countRequirement = sub.countRequirement\n        qualification = sub.qualification\n        relative_tolerance = sub.relativeTolerance\n        absolute_tolerance = sub.absoluteTolerance\n        allowed_occuranceRange = sub.allowedOccuranceRange\n    \n        \"\"\" Get solutions, measure execution time \"\"\"\n        try:\n            solution_student, exec_time_student = get_solution(monkeymodule, request, idx_main, Solution.student)\n            record_property(\"exec_time_student\", exec_time_student)\n            solution_reference, exec_time_reference = get_solution(monkeymodule, request, idx_main, Solution.reference)\n            record_property(\"exec_time_reference\", exec_time_reference)\n        except TimeoutError as e:\n            record_property(\"timeout\", True)\n            raise\n    \n        \"\"\" if test is graphics => get saved graphics object as solution \"\"\"\n        if testtype == TypeEnum.graphics:\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\n            TypeEnum.variable,\n            TypeEnum.graphics,\n            TypeEnum.error,\n            TypeEnum.warning,\n            TypeEnum.help,\n        ]:\n            \"\"\" get the student value \"\"\"\n            if name in solution_student:\n                val_student = solution_student[name]\n            else:\n                \"\"\" value not found, try eval \"\"\"\n                try:\n                    val_student = eval(name, solution_student)\n                except Exception as e:\n                    raise AssertionError(f\"Variable {name} not found in student namespace\")\n    \n            if qualification == QualificationEnum.verifyEqual:\n                \"\"\" get the reference value \"\"\"\n                if value is not None:\n                    val_reference = value\n                elif evalString is not None:\n                    try:\n                        val_reference = eval(evalString)\n                    except Exception as e:\n                        pytest.skip(reason=\"Evaluation of 'evalString' not possible\")\n                else:\n                    if name in solution_reference:\n                        val_reference = solution_reference[name]\n                    else:\n                        try:\n                            val_reference = eval(name, solution_reference)\n                        except Exception as e:\n                            raise AssertionError(f\"Variable {name} not found in reference namespace\")\n    \n                \"\"\" assert variable-type \"\"\"\n                type_student = type(val_student)\n                type_reference = type(val_reference)\n                assert type_student == type_reference, f\"Variable {name} has incorrect type, expected: {type_reference}, obtained {type_student}\"\n    \n                \"\"\" assert variable-value \"\"\"\n                failure_msg = f\"Variable {name} has incorrect value\"\n                if isinstance(val_student, (str, set, frozenset)):\n                    assert val_student == val_reference, failure_msg\n                elif isinstance(val_student, (DataFrame, Series)):\n                    assert val_student.equals(val_reference), failure_msg\n                elif isinstance(val_student, np.ndarray):\n                    try:\n                        if relative_tolerance is None and absolute_tolerance is None:\n                            np.testing.assert_allclose(val_student, val_reference)\n                        else:\n                            np.testing.assert_allclose(val_student, val_reference, rtol=relative_tolerance, atol=absolute_tolerance)\n                    except AssertionError as e:\n                        raise AssertionError(failure_msg)\n                else:\n                    \"\"\" attention: pytest.approx() does not support nested data structures, like: 'var7 = [[1, 22, 44]]' \"\"\"\n                    assert val_student == pytest.approx(val_reference, rel=relative_tolerance, abs=absolute_tolerance), failure_msg\n            elif qualification == QualificationEnum.matches:\n                assert str(val_student) == pattern, f\"Variable {name} does not match the specified pattern {pattern}\"\n            elif qualification == QualificationEnum.contains:\n                assert str(val_student).find(pattern) > -1, f\"Variable {name} does not contain the specified pattern {pattern}\"\n            elif qualification == QualificationEnum.startsWith:\n                assert str(val_student).startswith(pattern), f\"Variable {name} does not start with the specified pattern {pattern}\"\n            elif qualification == QualificationEnum.endsWith:\n                assert str(val_student).endswith(pattern), f\"Variable {name} does not end with the specified pattern {pattern}\"\n            elif qualification == QualificationEnum.count:\n>               assert str(val_student).count(pattern) == countRequirement, f\"Variable {name} does not contain the specified pattern {pattern} {countRequirement}-times\"\nE               AssertionError: Variable var2 does not contain the specified pattern - 1-times\nE               assert 0 == 1\nE                +  where 0 = <built-in method count of str object at 0x00000283A7D998F0>('-')\nE                +    where <built-in method count of str object at 0x00000283A7D998F0> = '_x1234567890'.count\nE                +      where '_x1234567890' = str('_x1234567890')\n\ncatester\\tests\\test_class.py:290: AssertionError"
        },
        {
          "name": "var2",
          "status": "COMPLETED",
          "result": "FAILED",
          "resultMessage": null,
          "details": null,
          "longrepr": "self = <tests.test_class.CodeabilityPythonTest object at 0x00000283A7C7E5F0>, request = <FixtureRequest for <Function test_entrypoint[testcases42]>>\nrecord_property = <function record_property.<locals>.append_property at 0x00000283A7EDC820>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x00000283AB2E19F0>, testcases = (5, 11)\n\n    def test_entrypoint(self, request, record_property, monkeymodule, testcases):\n        idx_main, idx_sub = testcases\n    \n        check_success_dependency(request, idx_main)\n    \n        _report = request.config.stash[report_key]\n        testsuite: CodeAbilityTestSuite = _report[\"testsuite\"]\n        specification: CodeAbilitySpecification = _report[\"specification\"]\n        main: CodeAbilityTestCollection = testsuite.properties.tests[idx_main]\n        sub: CodeAbilityTest = main.tests[idx_sub]\n    \n        dir_reference = specification.testInfo.referenceDirectory\n        dir_student = specification.testInfo.studentDirectory\n    \n        testtype = main.type\n        file = main.file\n    \n        name = sub.name\n        value = sub.value\n        evalString = sub.evalString\n        pattern = sub.pattern\n        countRequirement = sub.countRequirement\n        qualification = sub.qualification\n        relative_tolerance = sub.relativeTolerance\n        absolute_tolerance = sub.absoluteTolerance\n        allowed_occuranceRange = sub.allowedOccuranceRange\n    \n        \"\"\" Get solutions, measure execution time \"\"\"\n        try:\n            solution_student, exec_time_student = get_solution(monkeymodule, request, idx_main, Solution.student)\n            record_property(\"exec_time_student\", exec_time_student)\n            solution_reference, exec_time_reference = get_solution(monkeymodule, request, idx_main, Solution.reference)\n            record_property(\"exec_time_reference\", exec_time_reference)\n        except TimeoutError as e:\n            record_property(\"timeout\", True)\n            raise\n    \n        \"\"\" if test is graphics => get saved graphics object as solution \"\"\"\n        if testtype == TypeEnum.graphics:\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\n            TypeEnum.variable,\n            TypeEnum.graphics,\n            TypeEnum.error,\n            TypeEnum.warning,\n            TypeEnum.help,\n        ]:\n            \"\"\" get the student value \"\"\"\n            if name in solution_student:\n                val_student = solution_student[name]\n            else:\n                \"\"\" value not found, try eval \"\"\"\n                try:\n                    val_student = eval(name, solution_student)\n                except Exception as e:\n                    raise AssertionError(f\"Variable {name} not found in student namespace\")\n    \n            if qualification == QualificationEnum.verifyEqual:\n                \"\"\" get the reference value \"\"\"\n                if value is not None:\n                    val_reference = value\n                elif evalString is not None:\n                    try:\n                        val_reference = eval(evalString)\n                    except Exception as e:\n                        pytest.skip(reason=\"Evaluation of 'evalString' not possible\")\n                else:\n                    if name in solution_reference:\n                        val_reference = solution_reference[name]\n                    else:\n                        try:\n                            val_reference = eval(name, solution_reference)\n                        except Exception as e:\n                            raise AssertionError(f\"Variable {name} not found in reference namespace\")\n    \n                \"\"\" assert variable-type \"\"\"\n                type_student = type(val_student)\n                type_reference = type(val_reference)\n                assert type_student == type_reference, f\"Variable {name} has incorrect type, expected: {type_reference}, obtained {type_student}\"\n    \n                \"\"\" assert variable-value \"\"\"\n                failure_msg = f\"Variable {name} has incorrect value\"\n                if isinstance(val_student, (str, set, frozenset)):\n                    assert val_student == val_reference, failure_msg\n                elif isinstance(val_student, (DataFrame, Series)):\n                    assert val_student.equals(val_reference), failure_msg\n                elif isinstance(val_student, np.ndarray):\n                    try:\n                        if relative_tolerance is None and absolute_tolerance is None:\n                            np.testing.assert_allclose(val_student, val_reference)\n                        else:\n                            np.testing.assert_allclose(val_student, val_reference, rtol=relative_tolerance, atol=absolute_tolerance)\n                    except AssertionError as e:\n                        raise AssertionError(failure_msg)\n                else:\n                    \"\"\" attention: pytest.approx() does not support nested data structures, like: 'var7 = [[1, 22, 44]]' \"\"\"\n                    assert val_student == pytest.approx(val_reference, rel=relative_tolerance, abs=absolute_tolerance), failure_msg\n            elif qualification == QualificationEnum.matches:\n                assert str(val_student) == pattern, f\"Variable {name} does not match the specified pattern {pattern}\"\n            elif qualification == QualificationEnum.contains:\n                assert str(val_student).find(pattern) > -1, f\"Variable {name} does not contain the specified pattern {pattern}\"\n            elif qualification == QualificationEnum.startsWith:\n                assert str(val_student).startswith(pattern), f\"Variable {name} does not start with the specified pattern {pattern}\"\n            elif qualification == QualificationEnum.endsWith:\n                assert str(val_student).endswith(pattern), f\"Variable {name} does not end with the specified pattern {pattern}\"\n            elif qualification == QualificationEnum.count:\n                assert str(val_student).count(pattern) == countRequirement, f\"Variable {name} does not contain the specified pattern {pattern} {countRequirement}-times\"\n            elif qualification == QualificationEnum.regexp:\n                result = re.match(re.compile(fr\"{pattern}\"), str(val_student))\n>               assert result is not None, f\"Variable {name} does not match the compiled regular expression from the specified pattern {pattern}\"\nE               AssertionError: Variable var2 does not match the compiled regular expression from the specified pattern ^.*y.*$\nE               assert None is not None\n\ncatester\\tests\\test_class.py:293: AssertionError"
        }
      ]
    }
  ]
}