{
  "created": 1702375959.4499598,
  "duration": 1.0423707962036133,
  "exitcode": 1,
  "root": "i:\\PYTHON\\catester\\catester",
  "environment": {},
  "summary": {
    "failed": 4,
    "passed": 1,
    "total": 5,
    "collected": 5
  },
  "collectors": [
    {
      "nodeid": "",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "model/__init__.py",
          "type": "Package"
        },
        {
          "nodeid": "tests/__init__.py",
          "type": "Package"
        }
      ]
    },
    {
      "nodeid": "model/__init__.py",
      "outcome": "passed",
      "result": []
    },
    {
      "nodeid": "tests/test_class.py::CodeabilityTestSuite",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/test_class.py::CodeabilityTestSuite::test_entrypoint[testcases0]",
          "type": "Function",
          "lineno": 144
        },
        {
          "nodeid": "tests/test_class.py::CodeabilityTestSuite::test_entrypoint[testcases1]",
          "type": "Function",
          "lineno": 144
        },
        {
          "nodeid": "tests/test_class.py::CodeabilityTestSuite::test_entrypoint[testcases2]",
          "type": "Function",
          "lineno": 144
        },
        {
          "nodeid": "tests/test_class.py::CodeabilityTestSuite::test_entrypoint[testcases3]",
          "type": "Function",
          "lineno": 144
        },
        {
          "nodeid": "tests/test_class.py::CodeabilityTestSuite::test_entrypoint[testcases4]",
          "type": "Function",
          "lineno": 144
        }
      ]
    },
    {
      "nodeid": "tests/test_class.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/test_class.py::CodeabilityTestSuite",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "tests/__init__.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/test_class.py",
          "type": "Module"
        }
      ]
    }
  ],
  "tests": [
    {
      "nodeid": "tests/test_class.py::CodeabilityTestSuite::test_entrypoint[testcases0]",
      "lineno": 144,
      "outcome": "failed",
      "keywords": [
        "test_entrypoint[testcases0]",
        "testcases0",
        "CodeabilityTestSuite",
        "test_class.py",
        "tests/__init__.py",
        "catester"
      ],
      "setup": {
        "duration": 0.00449079999816604,
        "outcome": "passed",
        "stdout": "setup_class\nsetup_method\n"
      },
      "metadata": {
        "main_name": "Test Basic",
        "sub_name": "var1",
        "relative_tolerance": 0,
        "absolute_tolerance": 0,
        "allowed_occuranceRange": null,
        "qualification": "verifyEqual",
        "testtype": "variable",
        "failure_message": "Some or all tests failed",
        "success_message": "Congratulations! All tests passed"
      },
      "call": {
        "duration": 0.0010022000060416758,
        "outcome": "failed",
        "crash": {
          "path": "i:\\PYTHON\\catester\\catester\\tests\\test_class.py",
          "lineno": 194,
          "message": "KeyError: 0.30000000000000004"
        },
        "traceback": [
          {
            "path": "tests\\test_class.py",
            "lineno": 194,
            "message": "KeyError"
          }
        ],
        "longrepr": "self = <tests.test_class.CodeabilityTestSuite object at 0x0000026533112950>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x0000026533113220>\nconfig = {'abs_path_to_yaml': 'i:\\\\PYTHON\\\\catester\\\\examples\\\\ex1', 'testsuite': {'description': 'Checks variables', 'failureM...ency': None, 'qualification': <QualificationEnum.verifyEqual: 'verifyEqual'>, 'referenceCommandList': None, ...}, ...}}\ntestcases = (0, 0), json_metadata = {'absolute_tolerance': 0, 'allowed_occuranceRange': None, 'failure_message': 'Some or all tests failed', 'main_name': 'Test Basic', ...}\n\n    def test_entrypoint(self, monkeymodule, config, testcases, json_metadata):\n        idx_main, idx_sub = testcases\n        main = config[\"testsuite\"][\"properties\"][\"tests\"][idx_main]\n        sub = main[\"tests\"][idx_sub]\n        id = main[\"id\"] if main[\"id\"] is not None else str(idx_main + 1)\n    \n        ancestors = [sub, main, config[\"testsuite\"][\"properties\"]]\n        ancestors1 = [sub, main, config[\"testsuite\"]]\n    \n        relative_tolerance = get_inherited_property(\"relativeTolerance\", ancestors, 0)\n        absolute_tolerance = get_inherited_property(\"absoluteTolerance\", ancestors, 0)\n        allowed_occuranceRange = get_inherited_property(\"allowedOccuranceRange\", ancestors, None)\n        qualification = get_inherited_property(\"qualification\", ancestors, None)\n        testtype = get_inherited_property(\"type\", ancestors, None)\n        failure_message = get_inherited_property(\"failureMessage\", ancestors1, None)\n        success_message = get_inherited_property(\"successMessage\", ancestors1, None)\n    \n        file = main[\"file\"]\n    \n        name = sub[\"name\"]\n        value = sub[\"value\"]\n        evalString = sub[\"evalString\"]\n        pattern = sub[\"pattern\"]\n        countRequirement = sub[\"countRequirement\"]\n        options = sub[\"options\"]\n        verificationFunction = sub[\"verificationFunction\"]\n    \n        main_name = main[\"name\"]\n    \n        #json_metadata['sub'] = sub\n        json_metadata['main_name'] = main_name\n        json_metadata['sub_name'] = name\n        json_metadata['relative_tolerance'] = relative_tolerance\n        json_metadata['absolute_tolerance'] = absolute_tolerance\n        json_metadata['allowed_occuranceRange'] = allowed_occuranceRange\n        json_metadata['qualification'] = qualification\n        json_metadata['testtype'] = testtype\n        json_metadata['failure_message'] = failure_message\n        json_metadata['success_message'] = success_message\n    \n        solution_student = get_solution(monkeymodule, config, id, main, \"student\")\n        solution_reference = get_solution(monkeymodule, config, id, main, \"reference\")\n    \n        if testtype == \"graphics\":\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\"variable\", \"graphics\", \"error\", \"warning\", \"help\"]:\n            #assert name in solution_student, f\"Variable {name} not found in student namespace\"\n>           val_student = solution_student[eval(name, solution_student)]\nE           KeyError: 0.30000000000000004\n\ntests\\test_class.py:194: KeyError"
      },
      "teardown": {
        "duration": 0.0006599999906029552,
        "outcome": "passed",
        "stdout": "teardown_method\n"
      }
    },
    {
      "nodeid": "tests/test_class.py::CodeabilityTestSuite::test_entrypoint[testcases1]",
      "lineno": 144,
      "outcome": "failed",
      "keywords": [
        "test_entrypoint[testcases1]",
        "testcases1",
        "CodeabilityTestSuite",
        "test_class.py",
        "tests/__init__.py",
        "catester"
      ],
      "setup": {
        "duration": 0.0009355999936815351,
        "outcome": "passed",
        "stdout": "setup_method\n"
      },
      "metadata": {
        "main_name": "Test Basic",
        "sub_name": "var2",
        "relative_tolerance": 0,
        "absolute_tolerance": 0,
        "allowed_occuranceRange": null,
        "qualification": "verifyEqual",
        "testtype": "variable",
        "failure_message": "Some or all tests failed",
        "success_message": "Congratulations! All tests passed"
      },
      "call": {
        "duration": 0.0003816999960690737,
        "outcome": "failed",
        "crash": {
          "path": "i:\\PYTHON\\catester\\catester\\tests\\test_class.py",
          "lineno": 194,
          "message": "KeyError: '1'"
        },
        "traceback": [
          {
            "path": "tests\\test_class.py",
            "lineno": 194,
            "message": "KeyError"
          }
        ],
        "longrepr": "self = <tests.test_class.CodeabilityTestSuite object at 0x0000026533112B60>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x00000265331D3A30>\nconfig = {'abs_path_to_yaml': 'i:\\\\PYTHON\\\\catester\\\\examples\\\\ex1', 'testsuite': {'description': 'Checks variables', 'failureM...ency': None, 'qualification': <QualificationEnum.verifyEqual: 'verifyEqual'>, 'referenceCommandList': None, ...}, ...}}\ntestcases = (0, 1), json_metadata = {'absolute_tolerance': 0, 'allowed_occuranceRange': None, 'failure_message': 'Some or all tests failed', 'main_name': 'Test Basic', ...}\n\n    def test_entrypoint(self, monkeymodule, config, testcases, json_metadata):\n        idx_main, idx_sub = testcases\n        main = config[\"testsuite\"][\"properties\"][\"tests\"][idx_main]\n        sub = main[\"tests\"][idx_sub]\n        id = main[\"id\"] if main[\"id\"] is not None else str(idx_main + 1)\n    \n        ancestors = [sub, main, config[\"testsuite\"][\"properties\"]]\n        ancestors1 = [sub, main, config[\"testsuite\"]]\n    \n        relative_tolerance = get_inherited_property(\"relativeTolerance\", ancestors, 0)\n        absolute_tolerance = get_inherited_property(\"absoluteTolerance\", ancestors, 0)\n        allowed_occuranceRange = get_inherited_property(\"allowedOccuranceRange\", ancestors, None)\n        qualification = get_inherited_property(\"qualification\", ancestors, None)\n        testtype = get_inherited_property(\"type\", ancestors, None)\n        failure_message = get_inherited_property(\"failureMessage\", ancestors1, None)\n        success_message = get_inherited_property(\"successMessage\", ancestors1, None)\n    \n        file = main[\"file\"]\n    \n        name = sub[\"name\"]\n        value = sub[\"value\"]\n        evalString = sub[\"evalString\"]\n        pattern = sub[\"pattern\"]\n        countRequirement = sub[\"countRequirement\"]\n        options = sub[\"options\"]\n        verificationFunction = sub[\"verificationFunction\"]\n    \n        main_name = main[\"name\"]\n    \n        #json_metadata['sub'] = sub\n        json_metadata['main_name'] = main_name\n        json_metadata['sub_name'] = name\n        json_metadata['relative_tolerance'] = relative_tolerance\n        json_metadata['absolute_tolerance'] = absolute_tolerance\n        json_metadata['allowed_occuranceRange'] = allowed_occuranceRange\n        json_metadata['qualification'] = qualification\n        json_metadata['testtype'] = testtype\n        json_metadata['failure_message'] = failure_message\n        json_metadata['success_message'] = success_message\n    \n        solution_student = get_solution(monkeymodule, config, id, main, \"student\")\n        solution_reference = get_solution(monkeymodule, config, id, main, \"reference\")\n    \n        if testtype == \"graphics\":\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\"variable\", \"graphics\", \"error\", \"warning\", \"help\"]:\n            #assert name in solution_student, f\"Variable {name} not found in student namespace\"\n>           val_student = solution_student[eval(name, solution_student)]\nE           KeyError: '1'\n\ntests\\test_class.py:194: KeyError"
      },
      "teardown": {
        "duration": 0.0005595999828074127,
        "outcome": "passed",
        "stdout": "teardown_method\n"
      }
    },
    {
      "nodeid": "tests/test_class.py::CodeabilityTestSuite::test_entrypoint[testcases2]",
      "lineno": 144,
      "outcome": "failed",
      "keywords": [
        "test_entrypoint[testcases2]",
        "testcases2",
        "CodeabilityTestSuite",
        "test_class.py",
        "tests/__init__.py",
        "catester"
      ],
      "setup": {
        "duration": 0.0008710999973118305,
        "outcome": "passed",
        "stdout": "setup_method\n"
      },
      "metadata": {
        "main_name": "Test Basic",
        "sub_name": "var3",
        "relative_tolerance": 0,
        "absolute_tolerance": 0,
        "allowed_occuranceRange": null,
        "qualification": "verifyEqual",
        "testtype": "variable",
        "failure_message": "Some or all tests failed",
        "success_message": "Congratulations! All tests passed"
      },
      "call": {
        "duration": 0.0006444000173360109,
        "outcome": "failed",
        "crash": {
          "path": "i:\\PYTHON\\catester\\catester\\tests\\test_class.py",
          "lineno": 194,
          "message": "KeyError: True"
        },
        "traceback": [
          {
            "path": "tests\\test_class.py",
            "lineno": 194,
            "message": "KeyError"
          }
        ],
        "longrepr": "self = <tests.test_class.CodeabilityTestSuite object at 0x0000026533112C20>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x0000026533113640>\nconfig = {'abs_path_to_yaml': 'i:\\\\PYTHON\\\\catester\\\\examples\\\\ex1', 'testsuite': {'description': 'Checks variables', 'failureM...ency': None, 'qualification': <QualificationEnum.verifyEqual: 'verifyEqual'>, 'referenceCommandList': None, ...}, ...}}\ntestcases = (0, 2), json_metadata = {'absolute_tolerance': 0, 'allowed_occuranceRange': None, 'failure_message': 'Some or all tests failed', 'main_name': 'Test Basic', ...}\n\n    def test_entrypoint(self, monkeymodule, config, testcases, json_metadata):\n        idx_main, idx_sub = testcases\n        main = config[\"testsuite\"][\"properties\"][\"tests\"][idx_main]\n        sub = main[\"tests\"][idx_sub]\n        id = main[\"id\"] if main[\"id\"] is not None else str(idx_main + 1)\n    \n        ancestors = [sub, main, config[\"testsuite\"][\"properties\"]]\n        ancestors1 = [sub, main, config[\"testsuite\"]]\n    \n        relative_tolerance = get_inherited_property(\"relativeTolerance\", ancestors, 0)\n        absolute_tolerance = get_inherited_property(\"absoluteTolerance\", ancestors, 0)\n        allowed_occuranceRange = get_inherited_property(\"allowedOccuranceRange\", ancestors, None)\n        qualification = get_inherited_property(\"qualification\", ancestors, None)\n        testtype = get_inherited_property(\"type\", ancestors, None)\n        failure_message = get_inherited_property(\"failureMessage\", ancestors1, None)\n        success_message = get_inherited_property(\"successMessage\", ancestors1, None)\n    \n        file = main[\"file\"]\n    \n        name = sub[\"name\"]\n        value = sub[\"value\"]\n        evalString = sub[\"evalString\"]\n        pattern = sub[\"pattern\"]\n        countRequirement = sub[\"countRequirement\"]\n        options = sub[\"options\"]\n        verificationFunction = sub[\"verificationFunction\"]\n    \n        main_name = main[\"name\"]\n    \n        #json_metadata['sub'] = sub\n        json_metadata['main_name'] = main_name\n        json_metadata['sub_name'] = name\n        json_metadata['relative_tolerance'] = relative_tolerance\n        json_metadata['absolute_tolerance'] = absolute_tolerance\n        json_metadata['allowed_occuranceRange'] = allowed_occuranceRange\n        json_metadata['qualification'] = qualification\n        json_metadata['testtype'] = testtype\n        json_metadata['failure_message'] = failure_message\n        json_metadata['success_message'] = success_message\n    \n        solution_student = get_solution(monkeymodule, config, id, main, \"student\")\n        solution_reference = get_solution(monkeymodule, config, id, main, \"reference\")\n    \n        if testtype == \"graphics\":\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\"variable\", \"graphics\", \"error\", \"warning\", \"help\"]:\n            #assert name in solution_student, f\"Variable {name} not found in student namespace\"\n>           val_student = solution_student[eval(name, solution_student)]\nE           KeyError: True\n\ntests\\test_class.py:194: KeyError"
      },
      "teardown": {
        "duration": 0.0005514000076800585,
        "outcome": "passed",
        "stdout": "teardown_method\n"
      }
    },
    {
      "nodeid": "tests/test_class.py::CodeabilityTestSuite::test_entrypoint[testcases3]",
      "lineno": 144,
      "outcome": "failed",
      "keywords": [
        "test_entrypoint[testcases3]",
        "testcases3",
        "CodeabilityTestSuite",
        "test_class.py",
        "tests/__init__.py",
        "catester"
      ],
      "setup": {
        "duration": 0.0006815000087954104,
        "outcome": "passed",
        "stdout": "setup_method\n"
      },
      "metadata": {
        "main_name": "Test Basic",
        "sub_name": "var9[0]",
        "relative_tolerance": 0,
        "absolute_tolerance": 0,
        "allowed_occuranceRange": null,
        "qualification": "verifyEqual",
        "testtype": "variable",
        "failure_message": "Some or all tests failed",
        "success_message": "Congratulations! All tests passed"
      },
      "call": {
        "duration": 0.00036619999445974827,
        "outcome": "failed",
        "crash": {
          "path": "i:\\PYTHON\\catester\\catester\\tests\\test_class.py",
          "lineno": 194,
          "message": "KeyError: 1"
        },
        "traceback": [
          {
            "path": "tests\\test_class.py",
            "lineno": 194,
            "message": "KeyError"
          }
        ],
        "longrepr": "self = <tests.test_class.CodeabilityTestSuite object at 0x00000265331129B0>, monkeymodule = <_pytest.monkeypatch.MonkeyPatch object at 0x0000026533204A90>\nconfig = {'abs_path_to_yaml': 'i:\\\\PYTHON\\\\catester\\\\examples\\\\ex1', 'testsuite': {'description': 'Checks variables', 'failureM...ency': None, 'qualification': <QualificationEnum.verifyEqual: 'verifyEqual'>, 'referenceCommandList': None, ...}, ...}}\ntestcases = (0, 3), json_metadata = {'absolute_tolerance': 0, 'allowed_occuranceRange': None, 'failure_message': 'Some or all tests failed', 'main_name': 'Test Basic', ...}\n\n    def test_entrypoint(self, monkeymodule, config, testcases, json_metadata):\n        idx_main, idx_sub = testcases\n        main = config[\"testsuite\"][\"properties\"][\"tests\"][idx_main]\n        sub = main[\"tests\"][idx_sub]\n        id = main[\"id\"] if main[\"id\"] is not None else str(idx_main + 1)\n    \n        ancestors = [sub, main, config[\"testsuite\"][\"properties\"]]\n        ancestors1 = [sub, main, config[\"testsuite\"]]\n    \n        relative_tolerance = get_inherited_property(\"relativeTolerance\", ancestors, 0)\n        absolute_tolerance = get_inherited_property(\"absoluteTolerance\", ancestors, 0)\n        allowed_occuranceRange = get_inherited_property(\"allowedOccuranceRange\", ancestors, None)\n        qualification = get_inherited_property(\"qualification\", ancestors, None)\n        testtype = get_inherited_property(\"type\", ancestors, None)\n        failure_message = get_inherited_property(\"failureMessage\", ancestors1, None)\n        success_message = get_inherited_property(\"successMessage\", ancestors1, None)\n    \n        file = main[\"file\"]\n    \n        name = sub[\"name\"]\n        value = sub[\"value\"]\n        evalString = sub[\"evalString\"]\n        pattern = sub[\"pattern\"]\n        countRequirement = sub[\"countRequirement\"]\n        options = sub[\"options\"]\n        verificationFunction = sub[\"verificationFunction\"]\n    \n        main_name = main[\"name\"]\n    \n        #json_metadata['sub'] = sub\n        json_metadata['main_name'] = main_name\n        json_metadata['sub_name'] = name\n        json_metadata['relative_tolerance'] = relative_tolerance\n        json_metadata['absolute_tolerance'] = absolute_tolerance\n        json_metadata['allowed_occuranceRange'] = allowed_occuranceRange\n        json_metadata['qualification'] = qualification\n        json_metadata['testtype'] = testtype\n        json_metadata['failure_message'] = failure_message\n        json_metadata['success_message'] = success_message\n    \n        solution_student = get_solution(monkeymodule, config, id, main, \"student\")\n        solution_reference = get_solution(monkeymodule, config, id, main, \"reference\")\n    \n        if testtype == \"graphics\":\n            solution_student = solution_student[\"_graphics_object_\"]\n            solution_reference = solution_reference[\"_graphics_object_\"]\n    \n        if testtype in [\"variable\", \"graphics\", \"error\", \"warning\", \"help\"]:\n            #assert name in solution_student, f\"Variable {name} not found in student namespace\"\n>           val_student = solution_student[eval(name, solution_student)]\nE           KeyError: 1\n\ntests\\test_class.py:194: KeyError"
      },
      "teardown": {
        "duration": 0.0005837999924551696,
        "outcome": "passed",
        "stdout": "teardown_method\n"
      }
    },
    {
      "nodeid": "tests/test_class.py::CodeabilityTestSuite::test_entrypoint[testcases4]",
      "lineno": 144,
      "outcome": "passed",
      "keywords": [
        "test_entrypoint[testcases4]",
        "testcases4",
        "CodeabilityTestSuite",
        "test_class.py",
        "tests/__init__.py",
        "catester"
      ],
      "setup": {
        "duration": 0.0008525000012014061,
        "outcome": "passed",
        "stdout": "setup_method\n"
      },
      "metadata": {
        "main_name": "Existance of a file",
        "sub_name": "existance",
        "relative_tolerance": 0,
        "absolute_tolerance": 0,
        "allowed_occuranceRange": null,
        "qualification": "verifyEqual",
        "testtype": "exist",
        "failure_message": "Some or all tests failed",
        "success_message": "Congratulations! All tests passed"
      },
      "call": {
        "duration": 0.000905699998838827,
        "outcome": "passed"
      },
      "teardown": {
        "duration": 0.000651500013191253,
        "outcome": "passed",
        "stdout": "teardown_method\nteardown\nteardown_class\n"
      }
    }
  ],
  "_duration": 1.0423707962036133,
  "_metadata": {
    "Python": "3.10.11",
    "Platform": "Windows-10-10.0.19045-SP0",
    "Packages": {
      "pytest": "7.4.3",
      "pluggy": "1.3.0"
    },
    "Plugins": {
      "json-report": "1.5.0",
      "metadata": "3.0.0"
    },
    "yamlfile": "i:\\PYTHON\\catester\\examples\\ex1\\test2.yaml"
  },
  "_timestamp": "2023-12-12 11:12:39.449960",
  "_type": "python",
  "_version": "1.0",
  "_name": "Python Test suite",
  "_status": "COMPLETED",
  "_result": "ExitCode.TESTS_FAILED",
  "_tests": [
    {
      "name": "Test Basic",
      "variable": "var1",
      "status": "COMPLETED",
      "result": "FAILED",
      "details": "Some or all tests failed"
    },
    {
      "name": "Test Basic",
      "variable": "var2",
      "status": "COMPLETED",
      "result": "FAILED",
      "details": "Some or all tests failed"
    },
    {
      "name": "Test Basic",
      "variable": "var3",
      "status": "COMPLETED",
      "result": "FAILED",
      "details": "Some or all tests failed"
    },
    {
      "name": "Test Basic",
      "variable": "var9[0]",
      "status": "COMPLETED",
      "result": "FAILED",
      "details": "Some or all tests failed"
    },
    {
      "name": "Existance of a file",
      "variable": "existance",
      "status": "COMPLETED",
      "result": "PASSED",
      "details": "Congratulations! All tests passed"
    }
  ]
}